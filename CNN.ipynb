{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9c9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import activations\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261c3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e809dc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>HAM_0001751</td>\n",
       "      <td>ISIC_0024698</td>\n",
       "      <td>nv</td>\n",
       "      <td>consensus</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>HAM_0005276</td>\n",
       "      <td>ISIC_0027008</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>HAM_0005276</td>\n",
       "      <td>ISIC_0028790</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>HAM_0004103</td>\n",
       "      <td>ISIC_0028880</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>HAM_0004103</td>\n",
       "      <td>ISIC_0031309</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>HAM_0001164</td>\n",
       "      <td>ISIC_0030021</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>HAM_0001164</td>\n",
       "      <td>ISIC_0027118</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>HAM_0005684</td>\n",
       "      <td>ISIC_0027613</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>HAM_0005684</td>\n",
       "      <td>ISIC_0032468</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>HAM_0004330</td>\n",
       "      <td>ISIC_0029760</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>HAM_0004330</td>\n",
       "      <td>ISIC_0030555</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>HAM_0007526</td>\n",
       "      <td>ISIC_0030244</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>HAM_0007526</td>\n",
       "      <td>ISIC_0031827</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>HAM_0007051</td>\n",
       "      <td>ISIC_0031002</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>HAM_0007051</td>\n",
       "      <td>ISIC_0025668</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>HAM_0005518</td>\n",
       "      <td>ISIC_0032410</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>HAM_0002546</td>\n",
       "      <td>ISIC_0030579</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>HAM_0001785</td>\n",
       "      <td>ISIC_0034169</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>HAM_0001785</td>\n",
       "      <td>ISIC_0032941</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>HAM_0002909</td>\n",
       "      <td>ISIC_0032642</td>\n",
       "      <td>df</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id      image_id  dx    dx_type   age     sex     localization  \\\n",
       "64    HAM_0001751  ISIC_0024698  nv  consensus  70.0    male             face   \n",
       "1095  HAM_0005276  ISIC_0027008  df      histo  75.0    male             back   \n",
       "1096  HAM_0005276  ISIC_0028790  df      histo  75.0    male             back   \n",
       "1097  HAM_0004103  ISIC_0028880  df      histo  55.0    male  lower extremity   \n",
       "1098  HAM_0004103  ISIC_0031309  df      histo  55.0    male  lower extremity   \n",
       "1099  HAM_0001164  ISIC_0030021  df      histo  50.0  female  upper extremity   \n",
       "1100  HAM_0001164  ISIC_0027118  df      histo  50.0  female  upper extremity   \n",
       "1101  HAM_0005684  ISIC_0027613  df      histo  75.0  female  lower extremity   \n",
       "1102  HAM_0005684  ISIC_0032468  df      histo  75.0  female  lower extremity   \n",
       "1103  HAM_0004330  ISIC_0029760  df      histo  70.0    male  lower extremity   \n",
       "1104  HAM_0004330  ISIC_0030555  df      histo  70.0    male  lower extremity   \n",
       "1105  HAM_0007526  ISIC_0030244  df      histo  50.0    male  lower extremity   \n",
       "1106  HAM_0007526  ISIC_0031827  df      histo  50.0    male  lower extremity   \n",
       "1107  HAM_0007051  ISIC_0031002  df      histo  65.0    male  upper extremity   \n",
       "1108  HAM_0007051  ISIC_0025668  df      histo  65.0    male  upper extremity   \n",
       "1109  HAM_0005518  ISIC_0032410  df      histo  30.0    male  lower extremity   \n",
       "1110  HAM_0002546  ISIC_0030579  df      histo  55.0  female  upper extremity   \n",
       "1111  HAM_0001785  ISIC_0034169  df      histo  50.0    male  upper extremity   \n",
       "1112  HAM_0001785  ISIC_0032941  df      histo  50.0    male  upper extremity   \n",
       "1113  HAM_0002909  ISIC_0032642  df      histo  50.0    male  lower extremity   \n",
       "\n",
       "           dataset  \n",
       "64    vidir_modern  \n",
       "1095  vidir_modern  \n",
       "1096  vidir_modern  \n",
       "1097  vidir_modern  \n",
       "1098  vidir_modern  \n",
       "1099  vidir_modern  \n",
       "1100  vidir_modern  \n",
       "1101  vidir_modern  \n",
       "1102  vidir_modern  \n",
       "1103  vidir_modern  \n",
       "1104  vidir_modern  \n",
       "1105  vidir_modern  \n",
       "1106  vidir_modern  \n",
       "1107  vidir_modern  \n",
       "1108  vidir_modern  \n",
       "1109  vidir_modern  \n",
       "1110  vidir_modern  \n",
       "1111  vidir_modern  \n",
       "1112  vidir_modern  \n",
       "1113  vidir_modern  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['dx'] != 'bkl'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838dfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VAL = 2686\n",
    "NUM_TRN = 26860 - 2686\n",
    "TOTAL = 26860"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddfe42",
   "metadata": {},
   "source": [
    "(Warning for Sunlight, increased risk of cancer) Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "(Skin cancer) basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "(HARMLESS) benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "(HARMLESS) dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "(Not entirely harmless) melanocytic nevi (__nv__)   5\n",
    "\n",
    "(HARMLESS) vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "544945c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    lesion_id      image_id   dx dx_type   age   sex  \\\n",
       "0           0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male   \n",
       "1           1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male   \n",
       "2           2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male   \n",
       "3           3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male   \n",
       "4           4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male   \n",
       "\n",
       "  localization       dataset  risk  \n",
       "0        scalp  vidir_modern   0.0  \n",
       "1        scalp  vidir_modern   0.0  \n",
       "2        scalp  vidir_modern   0.0  \n",
       "3        scalp  vidir_modern   0.0  \n",
       "4          ear  vidir_modern   0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89856d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12233</td>\n",
       "      <td>12233</td>\n",
       "      <td>HAM_0001938</td>\n",
       "      <td>aug2_ISIC_0026245</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8496</td>\n",
       "      <td>8496</td>\n",
       "      <td>HAM_0002738</td>\n",
       "      <td>ISIC_0029438</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18870</td>\n",
       "      <td>18870</td>\n",
       "      <td>HAM_0001331</td>\n",
       "      <td>aug1_ISIC_0031400</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6915</td>\n",
       "      <td>6915</td>\n",
       "      <td>HAM_0003475</td>\n",
       "      <td>ISIC_0029825</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20641</td>\n",
       "      <td>20641</td>\n",
       "      <td>HAM_0001495</td>\n",
       "      <td>aug4_ISIC_0024913</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>85.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0    lesion_id           image_id     dx dx_type   age  \\\n",
       "0  12233       12233  HAM_0001938  aug2_ISIC_0026245    bkl   histo  45.0   \n",
       "1   8496        8496  HAM_0002738       ISIC_0029438     nv   histo  65.0   \n",
       "2  18870       18870  HAM_0001331  aug1_ISIC_0031400    bcc   histo  75.0   \n",
       "3   6915        6915  HAM_0003475       ISIC_0029825     nv   histo  70.0   \n",
       "4  20641       20641  HAM_0001495  aug4_ISIC_0024913  akiec   histo  85.0   \n",
       "\n",
       "      sex     localization       dataset  risk  \n",
       "0  female  lower extremity     rosendahl   0.0  \n",
       "1  female             face     rosendahl   1.0  \n",
       "2    male            chest  vidir_modern   3.0  \n",
       "3    male             back  vidir_modern   1.0  \n",
       "4    male             back  vidir_modern   2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093732b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 26860/26860 [00:04<00:00, 6065.87it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    sex = [1, 0, 0]\n",
    "    if df.iloc[i]['sex'] == 'male':\n",
    "        sex = [0, 1, 0]\n",
    "    elif df.iloc[i]['sex'] == 'female':\n",
    "        sex = [0, 0, 1]\n",
    "        \n",
    "    age = df.iloc[i]['age'] / 80\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array(sex)\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15)))# - 0.5))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15)))# - 0.5))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15)))# - 0.5))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15)))# - 0.5))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15)))# - 0.5))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15)))# - 0.5))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15)))# - 0.5))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15)))# - 0.5))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15)))# - 0.5))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15)))# - 0.5))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15)))# - 0.5))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15)))# - 0.5))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15)))# - 0.5))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15)))# - 0.5))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15)))# - 0.5))\n",
    "\n",
    "    feature_vector.append(feat)\n",
    "\n",
    "feat_X = np.array(feature_vector)\n",
    "\n",
    "del feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e70966",
   "metadata": {},
   "source": [
    "# 1000 Images for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9028ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.001,\n",
    "  patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645ba10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 3., 2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['risk'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980fe9f",
   "metadata": {},
   "source": [
    "# VGG model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1cf115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn = np.array(df['risk'])[:(-1 * NUM_VAL)]\n",
    "y_val = np.array(df['risk'])[(-1 * NUM_VAL):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f12be4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24174, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_trn = []\n",
    "for ele in y_trn:\n",
    "    new_y_trn.append(np.array(tf.one_hot(ele, 4)))\n",
    "    \n",
    "new_y_trn = np.array(new_y_trn)\n",
    "\n",
    "new_y_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d45d055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2686, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_val = []\n",
    "for ele in y_val:\n",
    "    new_y_val.append(np.array(tf.one_hot(ele, 4)))\n",
    "    \n",
    "new_y_val = np.array(new_y_val)\n",
    "\n",
    "new_y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d897cd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nVGG_load = VGG16(weights='imagenet', include_top=False)\\nmodel = models.Sequential()\\nmodel.add(VGG_load)\\n\\ndef VGG_preprocess(img):\\n    img = tf.image.resize(img, (224, 224))\\n    img = np.expand_dims(img, axis=0)\\n    img = tf.keras.applications.vgg16.preprocess_input(img)\\n    preds = np.array(model.predict(img))\\n\\n    return preds\\nvgg_gen = ImageDataGenerator(preprocessing_function=VGG_preprocess, dtype='float32')\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "VGG_load = VGG16(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "\n",
    "def VGG_preprocess(img):\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = np.array(model.predict(img))\n",
    "\n",
    "    return preds\n",
    "vgg_gen = ImageDataGenerator(preprocessing_function=VGG_preprocess, dtype='float32')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f47da7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                              | 0/26860 [00:00<?, ?it/s]2021-07-09 11:41:42.776530: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-09 11:41:42.776828: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 26860/26860 [26:50<00:00, 16.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "VGG_load = VGG16(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat = feat_X[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(25088)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, feat)))\n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "VGG_X = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4d450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_X_trn = np.array(VGG_X)[:(-1 * NUM_VAL)]\n",
    "\n",
    "VGG_X_val = np.array(VGG_X)[(-1 * NUM_VAL):]\n",
    "\n",
    "del VGG_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "361dcd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 24174/24174 [00:06<00:00, 4016.51it/s]\n"
     ]
    }
   ],
   "source": [
    "new_VGG_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    new_VGG_trn.append(np.array(VGG_X_trn[i]))\n",
    "\n",
    "new_VGG_trn = np.array(new_VGG_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c06dc4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 2686/2686 [00:00<00:00, 11006.30it/s]\n"
     ]
    }
   ],
   "source": [
    "new_VGG_val = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    new_VGG_val.append(np.array(VGG_X_val[i]))\n",
    "\n",
    "new_VGG_val = np.array(new_VGG_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e698978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = models.Sequential()\n",
    "vgg_model.add(layers.Dense(8192, activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01), \n",
    "                           bias_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "vgg_model.add(layers.Dense(4096, activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01), \n",
    "                           bias_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "vgg_model.add(layers.Dense(2048, activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01), \n",
    "                           bias_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "vgg_model.add(layers.Dense(1024, activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01), \n",
    "                           bias_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "vgg_model.add(layers.Dense(512, activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01), \n",
    "                           bias_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "vgg_model.add(layers.Dense(128, activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01), \n",
    "                           bias_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "vgg_model.add(layers.Dense(4, \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.01), \n",
    "                           bias_regularizer=tf.keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5801ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "756/756 [==============================] - 489s 641ms/step - loss: 229.6519 - accuracy: 0.5947 - val_loss: 230.6192 - val_accuracy: 0.7587\n",
      "Epoch 2/30\n",
      "756/756 [==============================] - 489s 643ms/step - loss: 230.8830 - accuracy: 0.8446 - val_loss: 232.8212 - val_accuracy: 0.7532\n",
      "Epoch 3/30\n",
      "756/756 [==============================] - 510s 674ms/step - loss: 232.8579 - accuracy: 0.9339 - val_loss: 235.0121 - val_accuracy: 0.8004\n",
      "Epoch 4/30\n",
      "756/756 [==============================] - 508s 669ms/step - loss: 235.0197 - accuracy: 0.9649 - val_loss: 237.2377 - val_accuracy: 0.8094\n",
      "Epoch 5/30\n",
      "756/756 [==============================] - 491s 647ms/step - loss: 237.1407 - accuracy: 0.9741 - val_loss: 239.5081 - val_accuracy: 0.7937\n",
      "Epoch 6/30\n",
      "756/756 [==============================] - 479s 633ms/step - loss: 239.3265 - accuracy: 0.9784 - val_loss: 241.4993 - val_accuracy: 0.8276\n",
      "Epoch 7/30\n",
      "756/756 [==============================] - 480s 634ms/step - loss: 241.2222 - accuracy: 0.9847 - val_loss: 243.2949 - val_accuracy: 0.8351\n",
      "Epoch 8/30\n",
      "756/756 [==============================] - 477s 630ms/step - loss: 243.0490 - accuracy: 0.9841 - val_loss: 245.2365 - val_accuracy: 0.8157\n",
      "Epoch 9/30\n",
      "756/756 [==============================] - 477s 630ms/step - loss: 244.9655 - accuracy: 0.9865 - val_loss: 247.1278 - val_accuracy: 0.8276\n",
      "Epoch 10/30\n",
      "756/756 [==============================] - 475s 628ms/step - loss: 246.8282 - accuracy: 0.9889 - val_loss: 249.0128 - val_accuracy: 0.8135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29c6523d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "vgg_model.fit(\n",
    "    vgg_gen.flow_from_dataframe(\n",
    "        df[:-2686],\n",
    "        directory='./data/HAM10000_images', \n",
    "        x_col='image_id', \n",
    "        y_col='risk', \n",
    "        target_size=(1, 7, 7, 512), \n",
    "        class_mode='categorical'),\n",
    "    \n",
    "    epochs=30, \n",
    "    \n",
    "    validation_data=vgg_gen.flow_from_dataframe(\n",
    "        df[-2686:],\n",
    "        directory='./data/HAM10000_images', \n",
    "        x_col='image_id', \n",
    "        y_col='risk', \n",
    "        target_size=(1, 7, 7, 512), \n",
    "        class_mode='categorical'), \n",
    "    \n",
    "    callbacks=[earlystop_callback])\n",
    "'''\n",
    "vgg_model.fit(new_VGG_trn, new_y_trn, \n",
    "              epochs=30, callbacks=[earlystop_callback],\n",
    "              validation_data=(new_VGG_val, new_y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_vgg_val = []\n",
    "\n",
    "temp_res_val = vgg_model.predict(new_VGG_val)\n",
    "del new_RES_val\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_vgg_val[i])\n",
    "    predict_y_vgg_val.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bfbfae",
   "metadata": {},
   "source": [
    "# ResNet setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4794f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                              | 0/26860 [00:00<?, ?it/s]2021-07-09 01:25:45.787445: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-09 01:25:45.787604: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n",
      "  0%|▍                                                                                                   | 123/26860 [00:11<40:45, 10.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/18/lbcwrdqx01l27lrh8q3rxlqh0000gn/T/ipykernel_96617/2768466399.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100352\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat = feat_X[i]    \n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, feat)))\n",
    "\n",
    "\n",
    "\n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "\n",
    "RES_X = preprocessed\n",
    "del preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40645b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_X_trn = np.array(RES_X)[:(-1 * NUM_VAL)]\n",
    "\n",
    "RES_X_val = np.array(RES_X)[(-1 * NUM_VAL):]\n",
    "\n",
    "del RES_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_RES_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    new_RES_trn.append(np.array(RES_X_trn[i]))\n",
    "\n",
    "new_RES_trn = np.array(new_RES_trn)\n",
    "del RES_X_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_RES_val = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    new_RES_val.append(np.array(RES_X_val[i]))\n",
    "\n",
    "new_RES_val = np.array(new_RES_val)\n",
    "\n",
    "del RES_X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = models.Sequential()\n",
    "#res_model.add(layers.Dense(8192, activation='relu'))\n",
    "#res_model.add(layers.Dense(4096, activation='relu'))\n",
    "res_model.add(layers.Dense(2048, activation='relu'))\n",
    "res_model.add(layers.Dense(1024, activation='relu'))\n",
    "#res_model.add(layers.Dense(512, activation='relu'))\n",
    "res_model.add(layers.Dense(128, activation='relu'))\n",
    "res_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "res_model.fit(new_RES_trn, new_y_trn, \n",
    "              epochs=30, callbacks=[earlystop_callback],\n",
    "              validation_data=(new_RES_val, new_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4cc3a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model.save('RES_Augmentated.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del resnet_load\n",
    "del model\n",
    "\n",
    "predict_y_res_val = []\n",
    "\n",
    "temp_res_val = res_model.predict(new_RES_val)\n",
    "del new_RES_val\n",
    "\n",
    "temp_res_trn = res_model.predict(new_RES_trn)\n",
    "del new_RES_trn\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_res_val[i])\n",
    "    predict_y_res_val.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474e60b",
   "metadata": {},
   "source": [
    "# Inception V3 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b1468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                              | 0/26860 [00:00<?, ?it/s]2021-07-09 08:00:35.694541: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-09 08:00:35.694689: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 26860/26860 [32:18<00:00, 13.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Inception\n",
    "preprocessed = []\n",
    "\n",
    "IV3_load = InceptionV3(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(IV3_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat = feat_X[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(131072)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, feat)))\n",
    "\n",
    "\n",
    "    \n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "IV3_X = preprocessed\n",
    "\n",
    "del preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f3abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IV3_X_trn = np.array(IV3_X)[:(-1 * NUM_VAL)]\n",
    "\n",
    "IV3_X_val = np.array(IV3_X)[(-1 * NUM_VAL):]\n",
    "\n",
    "del IV3_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a49d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 24174/24174 [01:16<00:00, 314.82it/s]\n"
     ]
    }
   ],
   "source": [
    "new_IV3_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    new_IV3_trn.append(np.array(IV3_X_trn[i]))\n",
    "\n",
    "new_IV3_trn = np.array(new_IV3_trn)\n",
    "\n",
    "del IV3_X_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fdfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_IV3_val = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    new_IV3_val.append(np.array(IV3_X_val[i]))\n",
    "\n",
    "new_IV3_val = np.array(new_IV3_val)\n",
    "\n",
    "del IV3_X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model = models.Sequential()\n",
    "#iv3_model.add(layers.Dense(8192, activation='relu'))\n",
    "iv3_model.add(layers.Dense(1024, activation='relu'))\n",
    "#iv3_model.add(layers.Dense(2048, activation='relu'))\n",
    "iv3_model.add(layers.Dense(256, activation='relu'))\n",
    "#iv3_model.add(layers.Dense(512, activation='relu'))\n",
    "#iv3_model.add(layers.Dense(128, activation='relu'))\n",
    "iv3_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "iv3_model.fit(new_IV3_trn, new_y_trn, \n",
    "              epochs=30, callbacks=[earlystop_callback],\n",
    "              validation_data=(new_IV3_val, new_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe31283",
   "metadata": {},
   "outputs": [],
   "source": [
    "del IV3_load\n",
    "del model\n",
    "\n",
    "predict_y_iv3_val = []\n",
    "\n",
    "temp_iv3_val = iv3_model.predict(new_IV3_val)\n",
    "del new_IV3_val\n",
    "\n",
    "temp_iv3_trn = iv3_model.predict(new_IV3_trn)\n",
    "del new_IV3_trn\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_iv3_val[i])\n",
    "    predict_y_iv3_val.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd322221",
   "metadata": {},
   "source": [
    "# Making the confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d311ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_iv3 = tf.math.confusion_matrix(np.array(y_val), np.array(predict_y_iv3_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1106aeb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_y_vgg_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/18/lbcwrdqx01l27lrh8q3rxlqh0000gn/T/ipykernel_2702/1648356217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm_vgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_y_vgg_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_y_vgg_val' is not defined"
     ]
    }
   ],
   "source": [
    "cm_vgg = tf.math.confusion_matrix(np.array(y_val), np.array(predict_y_vgg_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e941c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_res = tf.math.confusion_matrix(np.array(y_val), np.array(predict_y_res_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fcd7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cm_iv3 = np.array(cm_iv3).astype('float32')\n",
    "cm_vgg = np.array(cm_vgg).astype('float32')\n",
    "#cm_res = np.array(cm_res).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40d6d055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncm_res[0] = cm_res[0] / (1.0 * cm_res[0].sum())\\ncm_res[1] = cm_res[1] / (1.0 * cm_res[1].sum())\\ncm_res[2] = cm_res[2] / (1.0 * cm_res[2].sum())\\ncm_res[3] = cm_res[3] / (1.0 * cm_res[3].sum())\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cm_iv3[0] = cm_iv3[0] / (1.0 * cm_iv3[0].sum())\n",
    "cm_iv3[1] = cm_iv3[1] / (1.0 * cm_iv3[1].sum())\n",
    "cm_iv3[2] = cm_iv3[2] / (1.0 * cm_iv3[2].sum())\n",
    "cm_iv3[3] = cm_iv3[3] / (1.0 * cm_iv3[3].sum())\n",
    "\n",
    "'''\n",
    "cm_vgg[0] = cm_vgg[0] / (1.0 * cm_vgg[0].sum())\n",
    "cm_vgg[1] = cm_vgg[1] / (1.0 * cm_vgg[1].sum())\n",
    "cm_vgg[2] = cm_vgg[2] / (1.0 * cm_vgg[2].sum())\n",
    "cm_vgg[3] = cm_vgg[3] / (1.0 * cm_vgg[3].sum())\n",
    "\n",
    "'''\n",
    "cm_res[0] = cm_res[0] / (1.0 * cm_res[0].sum())\n",
    "cm_res[1] = cm_res[1] / (1.0 * cm_res[1].sum())\n",
    "cm_res[2] = cm_res[2] / (1.0 * cm_res[2].sum())\n",
    "cm_res[3] = cm_res[3] / (1.0 * cm_res[3].sum())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaef500",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_iv3, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e3c9334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_vgg, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f250af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_res, annot=True);\u0010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c9b65",
   "metadata": {},
   "source": [
    "# Stacking the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iv3, max_vgg, max_res = 0, 0, 0\n",
    "\n",
    "max_iv3 = np.amax([np.amax(temp_iv3_trn), np.amax(temp_iv3_val)])\n",
    "max_vgg = np.amax([np.amax(temp_vgg_trn), np.amax(temp_vgg_val)])\n",
    "max_res = np.amax([np.amax(temp_res_trn), np.amax(temp_res_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    feat = np.concatenate(( (temp_iv3_trn[i] / max_iv3), \n",
    "                            (temp_vgg_trn[i] / max_vgg), \n",
    "                            (temp_res_trn[i] / max_res) ))\n",
    "    new_X_trn.append(feat)\n",
    "    \n",
    "new_X_trn = np.array(new_X_trn)\n",
    "new_X_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48605e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_vgg_val.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6193d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_val = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    feat = np.concatenate(( (temp_iv3_val[i]), \n",
    "                            (temp_vgg_val[i]), \n",
    "                            (temp_res_val[i] ))\n",
    "    new_X_val.append(feat)\n",
    "    \n",
    "new_X_val = np.array(new_X_val)\n",
    "new_X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e19993",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = models.Sequential()\n",
    "\n",
    "final_model.add(layers.Dense(64, activation='relu'))\n",
    "final_model.add(layers.Dense(32, activation='relu'))\n",
    "final_model.add(layers.Dense(16, activation='relu'))\n",
    "final_model.add(layers.Dense(8, activation='relu'))\n",
    "final_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef8f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "final_model.fit(new_X_trn, new_y_trn, \n",
    "                epochs=10, callbacks=[earlystop_callback],\n",
    "                validation_data=(new_X_val, new_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_final_val = []\n",
    "temp_final_val = final_model.predict(new_X_val)\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_final_val[i])\n",
    "    predict_y_final_val.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0661483",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_final = tf.math.confusion_matrix(np.array(df['risk'])[(-1 * NUM_VAL):], np.array(predict_y_final_val))\n",
    "\n",
    "cm_final = np.array(cm_final).astype('float32')\n",
    "\n",
    "cm_final[0] = cm_final[0] / (1.0 * cm_final[0].sum())\n",
    "cm_final[1] = cm_final[1] / (1.0 * cm_final[1].sum())\n",
    "cm_final[2] = cm_final[2] / (1.0 * cm_final[2].sum())\n",
    "cm_final[3] = cm_final[3] / (1.0 * cm_final[3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf32f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_final, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c08ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68def8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3663b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a575bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d69737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de97e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86574dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "102eabe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7263588979895755"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(0, NUM_VAL):\n",
    "    if(y_val[i] == predict_y_vgg_val[i]):\n",
    "        count += 1\n",
    "count / NUM_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709220da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c830bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d14aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e12f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13dd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8324b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3923c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca237e14",
   "metadata": {},
   "source": [
    "# New Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effce3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61549d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, TOTAL):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,1, figsize=(15,30), sharex=True)\n",
    "\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 0.0], color='green', stat='probability', ax=axs[0]).set_title('risk 0')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 1.0], color='yellow', stat='probability', ax=axs[1]).set_title('risk 1')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 2.0], color='orange', stat='probability', ax=axs[2]).set_title('risk 2')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 3.0], color='red', stat='probability', ax=axs[3]).set_title('risk 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8907408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (150,200))\n",
    "    img = image.img_to_array(img) / 255.0\n",
    "    \n",
    "    \n",
    "    X.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = []\n",
    "\n",
    "for ele in df['risk']:\n",
    "    risk.append(tf.one_hot(int(ele), 4))\n",
    "    \n",
    "y = np.array(risk)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fee77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model = models.Sequential()\n",
    "ori_model.add(layers.Conv2D(64, (3, 3), activation='tanh', input_shape=(150,200,3)))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Conv2D(32, (3, 3), activation='tanh'))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Conv2D(16, (3, 3), activation='tanh'))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Flatten(name=\"feature_output\"))\n",
    "\n",
    "ori_model.add(layers.Dense(1024, activation='relu'))\n",
    "ori_model.add(layers.Dense(256, activation='relu'))\n",
    "ori_model.add(layers.Dense(64, activation='relu'))\n",
    "ori_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "ori_model.fit(X, y, epochs=25, validation_split=0.1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5119ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model.save('./models/feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"./models/feature\")\n",
    "\n",
    "\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=loaded_model.inputs,\n",
    "    outputs=loaded_model.get_layer(name=\"feature_output\").output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f93869",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    sex = 0 if df.iloc[i]['sex'] == 'male' else 1\n",
    "    age = df.iloc[i]['age']\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array([sex, age])\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15)))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15)))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15)))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15)))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15)))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15)))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15)))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15)))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15)))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15)))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15)))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15)))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15)))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15)))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15)))\n",
    "\n",
    "    feature_vector.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3013ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = feature_extractor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd43b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for img_feat, feat in zip(image_features, feature_vector):\n",
    "    X.append(np.concatenate((img_feat, feat)))\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94dcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=25, validation_split=0.1, batch_size=16, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd7666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675306d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c933e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186014f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef2a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ddfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2d761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ab873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8b6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f79c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6a057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd864c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ce2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, TOTAL):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append('no')\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append('lo')\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append('md')\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append('hi')\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d46b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_id'] = df['image_id'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16\n",
    "VGG_load = VGG16(weights='imagenet')\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f10b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=90, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True, preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
    "    vertical_flip=True, validation_split=0.1, zoom_range=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29185a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ead26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='training').class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='validation').class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {'hi':1, 'lo':0.25, 'md':5, 'no':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db25929",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = []\n",
    "\n",
    "for i in range(0, TOTAL):\n",
    "    sample_weights.append(class_weights[df.iloc[i]['risk']])\n",
    "    \n",
    "df['weight'] = sample_weights\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x=data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images', weight_col='weight',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='training'),\n",
    "    validation_data=data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images', weight_col='weight',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='validation'),\n",
    "    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38117486",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    sex = 0 if df.iloc[i]['sex'] == 'male' else 1\n",
    "    age = df.iloc[i]['age']\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array([sex, age])\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15)))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15)))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15)))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15)))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15)))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15)))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15)))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15)))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15)))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15)))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15)))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15)))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15)))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15)))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15)))\n",
    "\n",
    "    feature_vector.append(feat)\n",
    "feature_vector = np.array(feature_vector)\n",
    "\n",
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(feature_vector, return_counts=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=VGG_load.inputs,\n",
    "    outputs=VGG_load.layers[-4].output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = []\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat_vec = feature_vector[i]    \n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file, target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    # img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    img_feat = feature_extractor(img)\n",
    "\n",
    "    preprocessed.append(np.concatenate((img_feat, feat_vec)))\n",
    "    \n",
    "preprocessed = np.array(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78572b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohr = []\n",
    "\n",
    "for i in range(0, TOTAL):\n",
    "    risk = df.iloc[i]['risk']\n",
    "    \n",
    "    if risk == 'no':\n",
    "        ohr.append(tf.one_hot(0, 4))\n",
    "    elif risk == 'lo':\n",
    "        ohr.append(tf.one_hot(1, 4))\n",
    "    elif risk == 'md':\n",
    "        ohr.append(tf.one_hot(2, 4))\n",
    "    elif risk == 'hi':\n",
    "        ohr.append(tf.one_hot(3, 4))\n",
    "        \n",
    "ohr = np.array(ohr)\n",
    "\n",
    "ohr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ce71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = models.Sequential()\n",
    "new_model.add(layers.Dense(4096, activation='relu'))\n",
    "new_model.add(layers.Dense(2048, activation='relu'))\n",
    "new_model.add(layers.Dense(512, activation='relu'))\n",
    "new_model.add(layers.Dense(128, activation='relu'))\n",
    "new_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec650b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "new_model.fit(preprocessed, ohr, sample_weight=np.array(df['weight']), epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9aaa19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
