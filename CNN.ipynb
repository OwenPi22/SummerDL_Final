{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d9c9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "261c3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddfe42",
   "metadata": {},
   "source": [
    "Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "melanocytic nevi (__nv__)   5\n",
    "\n",
    "vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "544945c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  \n",
       "0  vidir_modern  \n",
       "1  vidir_modern  \n",
       "2  vidir_modern  \n",
       "3  vidir_modern  \n",
       "4  vidir_modern  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8a5e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10015/10015 [2:33:44<00:00,  1.09it/s] \n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "for file in tqdm(df['image_id']):\n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = model.predict(img)\n",
    "    preprocessed.append(preds)\n",
    "    \n",
    "df['VGG16'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88325339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10015/10015 [1:03:17<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Inception\n",
    "preprocessed = []\n",
    "\n",
    "model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "for file in tqdm(df['image_id']):\n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    preds = model.predict(img)\n",
    "    preprocessed.append(preds)\n",
    "    \n",
    "df['IV3'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a0493b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10015/10015 [2:05:42<00:00,  1.33it/s] \n"
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "preprocessed = []\n",
    "\n",
    "model = ResNet152V2(weights='imagenet', include_top=False)\n",
    "\n",
    "for file in tqdm(df['image_id']):\n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img)\n",
    "    preprocessed.append(preds)\n",
    "    \n",
    "df['resnet'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff649448",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(0, 10015):\n",
    "    dx = df.iloc[i]['dx']\n",
    "    if dx == 'akiec':\n",
    "        labels.append(tf.one_hot(0, 7))\n",
    "    elif dx == 'bcc':\n",
    "        labels.append(tf.one_hot(1, 7))\n",
    "    elif dx == 'bkl':\n",
    "        labels.append(tf.one_hot(2, 7))\n",
    "    elif dx == 'df':\n",
    "        labels.append(tf.one_hot(3, 7))\n",
    "    elif dx == 'mel':\n",
    "        labels.append(tf.one_hot(4, 7))\n",
    "    elif dx == 'nv':\n",
    "        labels.append(tf.one_hot(5, 7))\n",
    "    elif dx == 'vasc':\n",
    "        labels.append(tf.one_hot(6, 7))\n",
    "        \n",
    "df['one_hot'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf74db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b2329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cb1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73003e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df = pd.read_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40ceff98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>VGG16</th>\n",
       "      <th>IV3</th>\n",
       "      <th>resnet</th>\n",
       "      <th>one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[[[[ 0.          0.         11.025178    0.   ...</td>\n",
       "      <td>[[[[-0.         -0.          0.34455207 ...  0...</td>\n",
       "      <td>[[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[[[[ 0.          0.          1.2555903   0.724...</td>\n",
       "      <td>[[[[-0.         -0.         -0.         ...  0...</td>\n",
       "      <td>[[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[[[[ 0.          0.          6.3895373   0.   ...</td>\n",
       "      <td>[[[[-0.        -0.        -0.        ...  0.76...</td>\n",
       "      <td>[[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[[[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ...</td>\n",
       "      <td>[[[[ 1.1053773  -0.         -0.         ...  0...</td>\n",
       "      <td>[[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[[[[ 0.          0.          0.          0.   ...</td>\n",
       "      <td>[[[[-0.         -0.          0.10026377 ...  0...</td>\n",
       "      <td>[[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset                                              VGG16  \\\n",
       "0  vidir_modern  [[[[ 0.          0.         11.025178    0.   ...   \n",
       "1  vidir_modern  [[[[ 0.          0.          1.2555903   0.724...   \n",
       "2  vidir_modern  [[[[ 0.          0.          6.3895373   0.   ...   \n",
       "3  vidir_modern  [[[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ...   \n",
       "4  vidir_modern  [[[[ 0.          0.          0.          0.   ...   \n",
       "\n",
       "                                                 IV3  \\\n",
       "0  [[[[-0.         -0.          0.34455207 ...  0...   \n",
       "1  [[[[-0.         -0.         -0.         ...  0...   \n",
       "2  [[[[-0.        -0.        -0.        ...  0.76...   \n",
       "3  [[[[ 1.1053773  -0.         -0.         ...  0...   \n",
       "4  [[[[-0.         -0.          0.10026377 ...  0...   \n",
       "\n",
       "                                              resnet  \\\n",
       "0  [[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....   \n",
       "1  [[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....   \n",
       "2  [[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....   \n",
       "3  [[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....   \n",
       "4  [[[[-0. -0. -0. ... -0. -0. -0.], [-0. -0. -0....   \n",
       "\n",
       "                                             one_hot  \n",
       "0  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  \n",
       "1  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  \n",
       "2  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  \n",
       "3  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  \n",
       "4  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c48caed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['one_hot'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96b7bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_X = np.array(df['VGG16'])\n",
    "IV3_X = np.array(df['IV3'])\n",
    "RES_X = np.array(df['resnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a30f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['one_hot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd8646c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.       ,  0.       , 11.025178 , ...,  0.       ,\n",
       "           1.7154353,  0.       ],\n",
       "         [ 0.       ,  0.       ,  5.5877066, ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       , 13.220544 , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       , 10.496432 , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  5.7669587, ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       , 10.018325 , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           3.4823925,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           3.2159264,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           3.7883434,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           1.5135566,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  3.0512648, ...,  0.       ,\n",
       "           0.4914935,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  0.       ,  3.7033737, ...,  0.       ,\n",
       "          11.835646 ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           6.4553638,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           2.8949115,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  7.153902 , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  9.489576 , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  0.       , 11.747975 , ...,  0.       ,\n",
       "          12.086928 ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  9.830614 , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       , 11.546958 , ...,  0.       ,\n",
       "           0.       ,  0.       ]]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bc5e031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 8, 2048)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IV3_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a92e6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(7,7,512)))\n",
    "model.add(layers.Dense(8192, activation='relu'))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(2048, activation='relu'))\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b34a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_VGG = []\n",
    "for x in VGG_X:\n",
    "    new_VGG.append(x.reshape(7, 7, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a08b51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_VGG = np.asarray(new_VGG).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5af090b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 7, 7, 512)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_VGG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bab24b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 7)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y = []\n",
    "for ele in y:\n",
    "    new_y.append(np.array(ele))\n",
    "    \n",
    "new_y = np.array(new_y)\n",
    "\n",
    "new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "038177fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10015 samples\n",
      "Epoch 1/10\n",
      "10015/10015 [==============================] - 527s 53ms/sample - loss: 2.4840 - accuracy: 0.7008\n",
      "Epoch 2/10\n",
      "10015/10015 [==============================] - 526s 53ms/sample - loss: 0.6617 - accuracy: 0.7854\n",
      "Epoch 3/10\n",
      "10015/10015 [==============================] - 533s 53ms/sample - loss: 0.4506 - accuracy: 0.8581\n",
      "Epoch 4/10\n",
      "10015/10015 [==============================] - 534s 53ms/sample - loss: 0.3527 - accuracy: 0.9021\n",
      "Epoch 5/10\n",
      "10015/10015 [==============================] - 525s 52ms/sample - loss: 0.2618 - accuracy: 0.9206\n",
      "Epoch 6/10\n",
      "10015/10015 [==============================] - 516s 52ms/sample - loss: 0.1727 - accuracy: 0.9506\n",
      "Epoch 7/10\n",
      "10015/10015 [==============================] - 508s 51ms/sample - loss: 0.1598 - accuracy: 0.9548\n",
      "Epoch 8/10\n",
      "10015/10015 [==============================] - 506s 51ms/sample - loss: 0.1214 - accuracy: 0.9641\n",
      "Epoch 9/10\n",
      "10015/10015 [==============================] - 498s 50ms/sample - loss: 0.1212 - accuracy: 0.9659\n",
      "Epoch 10/10\n",
      "10015/10015 [==============================] - 503s 50ms/sample - loss: 0.0921 - accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fddd41630d0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(new_VGG, new_y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "31e4deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_RES = []\n",
    "for x in RES_X:\n",
    "    new_RES.append(x.reshape(7, 7, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8122a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = models.Sequential()\n",
    "res_model.add(layers.Flatten(input_shape=(7,7,2048)))\n",
    "res_model.add(layers.Dense(8192, activation='relu'))\n",
    "res_model.add(layers.Dense(4096, activation='relu'))\n",
    "res_model.add(layers.Dense(2048, activation='relu'))\n",
    "res_model.add(layers.Dense(1024, activation='relu'))\n",
    "res_model.add(layers.Dense(512, activation='relu'))\n",
    "res_model.add(layers.Dense(128, activation='relu'))\n",
    "res_model.add(layers.Dense(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "44a81370",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_4_input to have 4 dimensions, but got array with shape (10015, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-aa7dd80a9cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRES_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected flatten_4_input to have 4 dimensions, but got array with shape (10015, 1)"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(RES_X, new_y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f7563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
