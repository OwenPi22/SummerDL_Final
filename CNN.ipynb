{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9c9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import activations\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "261c3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddfe42",
   "metadata": {},
   "source": [
    "(Warning for Sunlight, increased risk of cancer) Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "(Skin cancer) basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "(HARMLESS) benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "(HARMLESS) dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "(Not entirely harmless) melanocytic nevi (__nv__)   5\n",
    "\n",
    "(HARMLESS) vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd5f5d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1956"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of cases where we can use LSTM\n",
    "\n",
    "(df['lesion_id'].value_counts() > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544945c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  \n",
       "0  vidir_modern  \n",
       "1  vidir_modern  \n",
       "2  vidir_modern  \n",
       "3  vidir_modern  \n",
       "4  vidir_modern  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89856d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6790</td>\n",
       "      <td>HAM_0004318</td>\n",
       "      <td>ISIC_0031678</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3921</td>\n",
       "      <td>HAM_0004015</td>\n",
       "      <td>ISIC_0027892</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>50.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7038</td>\n",
       "      <td>HAM_0003892</td>\n",
       "      <td>ISIC_0028045</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3017</td>\n",
       "      <td>HAM_0002877</td>\n",
       "      <td>ISIC_0030435</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9722</td>\n",
       "      <td>HAM_0004012</td>\n",
       "      <td>ISIC_0025831</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id     dx    dx_type   age     sex  \\\n",
       "0   6790  HAM_0004318  ISIC_0031678     nv      histo  45.0  female   \n",
       "1   3921  HAM_0004015  ISIC_0027892     nv  follow_up  50.0  female   \n",
       "2   7038  HAM_0003892  ISIC_0028045     nv      histo  25.0  female   \n",
       "3   3017  HAM_0002877  ISIC_0030435     nv  follow_up  50.0    male   \n",
       "4   9722  HAM_0004012  ISIC_0025831  akiec      histo  65.0  female   \n",
       "\n",
       "      localization        dataset  risk  \n",
       "0             back   vidir_modern   1.0  \n",
       "1  lower extremity  vidir_molemax   1.0  \n",
       "2  lower extremity   vidir_modern   1.0  \n",
       "3            trunk  vidir_molemax   1.0  \n",
       "4             face      rosendahl   2.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3064aeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['back', 'chest', 'trunk', 'unknown', 'abdomen', 'upper extremity',\n",
       "       'foot', 'lower extremity', 'ear', 'face', 'neck', 'scalp',\n",
       "       'genital', 'hand', 'acral'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['localization'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e38650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    loc = df.iloc[i]['localization']\n",
    "    if loc == 'abdomen':\n",
    "        temp.append(tf.one_hot(0, 15))\n",
    "    elif loc == 'scalp':\n",
    "        temp.append(tf.one_hot(1, 15))\n",
    "    elif loc == 'lower extremity':\n",
    "        temp.append(tf.one_hot(2, 15))\n",
    "    elif loc == 'trunk':\n",
    "        temp.append(tf.one_hot(3, 15))\n",
    "    elif loc == 'upper extremity':\n",
    "        temp.append(tf.one_hot(4, 15))\n",
    "    elif loc == 'back':\n",
    "        temp.append(tf.one_hot(5, 15))\n",
    "    elif loc == 'neck':\n",
    "        temp.append(tf.one_hot(6, 15))\n",
    "    elif loc == 'face':\n",
    "        temp.append(tf.one_hot(7, 15))\n",
    "    elif loc == 'chest':\n",
    "        temp.append(tf.one_hot(8, 15))\n",
    "    elif loc == 'foot':\n",
    "        temp.append(tf.one_hot(9, 15))\n",
    "    elif loc == 'ear':\n",
    "        temp.append(tf.one_hot(10, 15))\n",
    "    elif loc == 'unknown':\n",
    "        temp.append(tf.one_hot(11, 15))\n",
    "    elif loc == 'hand':\n",
    "        temp.append(tf.one_hot(12, 15))\n",
    "    elif loc == 'acral':\n",
    "        temp.append(tf.one_hot(13, 15))\n",
    "    elif loc == 'genital':\n",
    "        temp.append(tf.one_hot(14, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958a6fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_loc = np.array(temp)\n",
    "\n",
    "one_hot_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a5e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10015 [00:01<3:00:36,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/10015 [00:02<2:47:07,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/10015 [00:02<2:40:20,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/10015 [00:03<2:37:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/10015 [00:04<2:35:18,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/10015 [00:05<2:34:05,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/10015 [00:06<2:33:19,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/10015 [00:07<2:32:51,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/10015 [00:08<2:33:02,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/10015 [00:09<2:32:35,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 11/10015 [00:10<2:32:22,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 12/10015 [00:11<2:32:29,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 13/10015 [00:12<2:34:34,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25103,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/10015 [00:13<2:47:14,  1.00s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7d9ef0bec525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25088\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "VGG_load = VGG16(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    ohl = one_hot_loc[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(25088)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['VGG16'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88325339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/10015 [00:10<1:56:39,  1.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dbd020b55443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m131072\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inception\n",
    "preprocessed = []\n",
    "\n",
    "IV3_load = InceptionV3(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(IV3_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    ohl = one_hot_loc[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(131072)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['IV3'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a0493b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/10015 [00:13<6:09:56,  2.22s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-84d99bdb0263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100352\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    ohl = one_hot_loc[i]    \n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['resnet'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff649448",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(0, 10015):\n",
    "    dx = df.iloc[i]['dx']\n",
    "    if dx == 'akiec':\n",
    "        labels.append(tf.one_hot(0, 7))\n",
    "    elif dx == 'bcc':\n",
    "        labels.append(tf.one_hot(1, 7))\n",
    "    elif dx == 'bkl':\n",
    "        labels.append(tf.one_hot(2, 7))\n",
    "    elif dx == 'df':\n",
    "        labels.append(tf.one_hot(3, 7))\n",
    "    elif dx == 'mel':\n",
    "        labels.append(tf.one_hot(4, 7))\n",
    "    elif dx == 'nv':\n",
    "        labels.append(tf.one_hot(5, 7))\n",
    "    elif dx == 'vasc':\n",
    "        labels.append(tf.one_hot(6, 7))\n",
    "        \n",
    "df['one_hot'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4cf74db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8226</td>\n",
       "      <td>HAM_0001212</td>\n",
       "      <td>ISIC_0024846</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vienna_dias</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2819</td>\n",
       "      <td>HAM_0007557</td>\n",
       "      <td>ISIC_0030964</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8102</td>\n",
       "      <td>HAM_0005232</td>\n",
       "      <td>ISIC_0025993</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>chest</td>\n",
       "      <td>vienna_dias</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5582</td>\n",
       "      <td>HAM_0003557</td>\n",
       "      <td>ISIC_0026973</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8077</td>\n",
       "      <td>HAM_0001136</td>\n",
       "      <td>ISIC_0031848</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>vienna_dias</td>\n",
       "      <td>(tf.Tensor(0.0, shape=(), dtype=float32), tf.T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age     sex  \\\n",
       "0   8226  HAM_0001212  ISIC_0024846   nv      histo  40.0  female   \n",
       "1   2819  HAM_0007557  ISIC_0030964  bcc      histo  55.0    male   \n",
       "2   8102  HAM_0005232  ISIC_0025993   nv      histo  25.0  female   \n",
       "3   5582  HAM_0003557  ISIC_0026973   nv  follow_up  75.0    male   \n",
       "4   8077  HAM_0001136  ISIC_0031848   nv      histo  40.0    male   \n",
       "\n",
       "  localization        dataset  \\\n",
       "0         back    vienna_dias   \n",
       "1         back      rosendahl   \n",
       "2        chest    vienna_dias   \n",
       "3        trunk  vidir_molemax   \n",
       "4        chest    vienna_dias   \n",
       "\n",
       "                                             one_hot  \n",
       "0  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  \n",
       "1  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  \n",
       "2  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  \n",
       "3  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  \n",
       "4  (tf.Tensor(0.0, shape=(), dtype=float32), tf.T...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21be79",
   "metadata": {},
   "source": [
    "(Warning for Sunlight, increased risk of cancer) Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "(Skin cancer) basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "(HARMLESS) benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "(HARMLESS) dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "(Not entirely harmless) melanocytic nevi (__nv__)   5\n",
    "\n",
    "(HARMLESS) vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d4b2329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  risk  \n",
       "0  vidir_modern   0.0  \n",
       "1  vidir_modern   0.0  \n",
       "2  vidir_modern   0.0  \n",
       "3  vidir_modern   0.0  \n",
       "4  vidir_modern   0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "363cb1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mel    1113\n",
       "bcc     514\n",
       "Name: dx, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['risk'] == 3.0]['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96b7bf1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'VGG16'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'VGG16'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-df4298bbe9ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVGG_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VGG16'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mIV3_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IV3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRES_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resnet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'VGG16'"
     ]
    }
   ],
   "source": [
    "VGG_X = np.array(df['VGG16'])\n",
    "IV3_X = np.array(df['IV3'])\n",
    "RES_X = np.array(df['resnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a30f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = np.array(df['one_hot'])\n",
    "\n",
    "y = np.array(df['risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a92e6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = models.Sequential()\n",
    "vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "vgg_model.add(layers.Dense(2048, activation='relu'))\n",
    "vgg_model.add(layers.Dense(1024, activation='relu'))\n",
    "vgg_model.add(layers.Dense(512, activation='relu'))\n",
    "vgg_model.add(layers.Dense(128, activation='relu'))\n",
    "vgg_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e3316d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_VGG = np.asarray(new_VGG).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "30cc39d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 7, 7, 512)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_VGG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "97c802b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 7)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y = []\n",
    "for ele in y:\n",
    "    new_y.append(np.array(ele))\n",
    "    \n",
    "new_y = np.array(new_y)\n",
    "\n",
    "new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f5801ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10015 samples\n",
      "Epoch 1/10\n",
      "   96/10015 [..............................] - ETA: 11:09 - loss: 102.7127 - accuracy: 0.6094"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-49ab87f527a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_VGG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(new_VGG, new_y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "acf3646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = models.Sequential()\n",
    "res_model.add(layers.Dense(8192, activation='relu'))\n",
    "res_model.add(layers.Dense(4096, activation='relu'))\n",
    "res_model.add(layers.Dense(2048, activation='relu'))\n",
    "res_model.add(layers.Dense(1024, activation='relu'))\n",
    "res_model.add(layers.Dense(512, activation='relu'))\n",
    "res_model.add(layers.Dense(128, activation='relu'))\n",
    "res_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "768b87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10015 samples\n",
      "Epoch 1/10\n",
      "   32/10015 [..............................] - ETA: 1:34:13"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-5146bc07bb6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mres_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_RES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "res_model.fit(new_RES, new_y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8308fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model = models.Sequential()\n",
    "iv3_model.add(layers.Dense(8192, activation='relu'))\n",
    "iv3_model.add(layers.Dense(4096, activation='relu'))\n",
    "iv3_model.add(layers.Dense(2048, activation='relu'))\n",
    "iv3_model.add(layers.Dense(1024, activation='relu'))\n",
    "iv3_model.add(layers.Dense(512, activation='relu'))\n",
    "iv3_model.add(layers.Dense(128, activation='relu'))\n",
    "iv3_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6f400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9013 samples, validate on 1002 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "iv3_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "iv3_model.fit(new_IV3, new_y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bbb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b5eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d311ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95cc198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c64e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6d055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c920e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b06ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9d062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3454d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34432f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c9334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f250af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056b13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b662c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca237e14",
   "metadata": {},
   "source": [
    "# New Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37a3417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "effce3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8821</td>\n",
       "      <td>HAM_0006366</td>\n",
       "      <td>ISIC_0030732</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7580</td>\n",
       "      <td>HAM_0001026</td>\n",
       "      <td>ISIC_0033743</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>foot</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6473</td>\n",
       "      <td>HAM_0002059</td>\n",
       "      <td>ISIC_0028061</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1553</td>\n",
       "      <td>HAM_0000611</td>\n",
       "      <td>ISIC_0033804</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>30.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8823</td>\n",
       "      <td>HAM_0002025</td>\n",
       "      <td>ISIC_0025169</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>5.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>rosendahl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age     sex  \\\n",
       "0   8821  HAM_0006366  ISIC_0030732   nv      histo  65.0  female   \n",
       "1   7580  HAM_0001026  ISIC_0033743   nv      histo  20.0  female   \n",
       "2   6473  HAM_0002059  ISIC_0028061   nv  follow_up  40.0  female   \n",
       "3   1553  HAM_0000611  ISIC_0033804  mel      histo  30.0  female   \n",
       "4   8823  HAM_0002025  ISIC_0025169   nv      histo   5.0    male   \n",
       "\n",
       "      localization        dataset  \n",
       "0  upper extremity      rosendahl  \n",
       "1             foot   vidir_modern  \n",
       "2            trunk  vidir_molemax  \n",
       "3             back   vidir_modern  \n",
       "4            scalp      rosendahl  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61549d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8821</td>\n",
       "      <td>HAM_0006366</td>\n",
       "      <td>ISIC_0030732</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7580</td>\n",
       "      <td>HAM_0001026</td>\n",
       "      <td>ISIC_0033743</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>20.0</td>\n",
       "      <td>female</td>\n",
       "      <td>foot</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6473</td>\n",
       "      <td>HAM_0002059</td>\n",
       "      <td>ISIC_0028061</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1553</td>\n",
       "      <td>HAM_0000611</td>\n",
       "      <td>ISIC_0033804</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>30.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8823</td>\n",
       "      <td>HAM_0002025</td>\n",
       "      <td>ISIC_0025169</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>5.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age     sex  \\\n",
       "0   8821  HAM_0006366  ISIC_0030732   nv      histo  65.0  female   \n",
       "1   7580  HAM_0001026  ISIC_0033743   nv      histo  20.0  female   \n",
       "2   6473  HAM_0002059  ISIC_0028061   nv  follow_up  40.0  female   \n",
       "3   1553  HAM_0000611  ISIC_0033804  mel      histo  30.0  female   \n",
       "4   8823  HAM_0002025  ISIC_0025169   nv      histo   5.0    male   \n",
       "\n",
       "      localization        dataset  risk  \n",
       "0  upper extremity      rosendahl   1.0  \n",
       "1             foot   vidir_modern   1.0  \n",
       "2            trunk  vidir_molemax   1.0  \n",
       "3             back   vidir_modern   3.0  \n",
       "4            scalp      rosendahl   1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a92062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c245ac32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'risk 3')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x2160 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(4,1, figsize=(15,30), sharex=True)\n",
    "\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 0.0], color='green', stat='probability', ax=axs[0]).set_title('risk 0')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 1.0], color='yellow', stat='probability', ax=axs[1]).set_title('risk 1')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 2.0], color='orange', stat='probability', ax=axs[2]).set_title('risk 2')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 3.0], color='red', stat='probability', ax=axs[3]).set_title('risk 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8907408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10015/10015 [01:01<00:00, 162.65it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (150,200))\n",
    "    img = image.img_to_array(img) / 255.0\n",
    "    \n",
    "    \n",
    "    X.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88fd32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 150, 200, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8202bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "\n",
    "for ele in df['risk']:\n",
    "    risk.append(tf.one_hot(int(ele), 4))\n",
    "    \n",
    "y = np.array(risk)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4fee77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model = models.Sequential()\n",
    "ori_model.add(layers.Conv2D(64, (3, 3), activation='tanh', input_shape=(150,200,3)))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Conv2D(32, (3, 3), activation='tanh'))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Conv2D(16, (3, 3), activation='tanh'))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Flatten(name=\"feature_output\"))\n",
    "\n",
    "ori_model.add(layers.Dense(1024, activation='relu'))\n",
    "ori_model.add(layers.Dense(256, activation='relu'))\n",
    "ori_model.add(layers.Dense(64, activation='relu'))\n",
    "ori_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230d7536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9013 samples, validate on 1002 samples\n",
      "Epoch 1/10\n",
      "9013/9013 [==============================] - 1395s 155ms/sample - loss: 0.8991 - accuracy: 0.6574 - val_loss: 1.8887 - val_accuracy: 0.2166\n",
      "Epoch 2/10\n",
      "9013/9013 [==============================] - 1399s 155ms/sample - loss: 0.7943 - accuracy: 0.6831 - val_loss: 7.8821 - val_accuracy: 0.6487\n",
      "Epoch 3/10\n",
      "9013/9013 [==============================] - 1506s 167ms/sample - loss: 0.7726 - accuracy: 0.6788 - val_loss: 0.8484 - val_accuracy: 0.6527\n",
      "Epoch 4/10\n",
      "9013/9013 [==============================] - 1506s 167ms/sample - loss: 0.7592 - accuracy: 0.6847 - val_loss: 2.2043 - val_accuracy: 0.6487\n",
      "Epoch 5/10\n",
      "9013/9013 [==============================] - 1505s 167ms/sample - loss: 0.7377 - accuracy: 0.6937 - val_loss: 4.0482 - val_accuracy: 0.6487\n",
      "Epoch 6/10\n",
      "9013/9013 [==============================] - 1505s 167ms/sample - loss: 0.7242 - accuracy: 0.7004 - val_loss: 1.0555 - val_accuracy: 0.6487\n",
      "Epoch 7/10\n",
      "9013/9013 [==============================] - 1505s 167ms/sample - loss: 0.6911 - accuracy: 0.7156 - val_loss: 0.8887 - val_accuracy: 0.6597\n",
      "Epoch 8/10\n",
      "9013/9013 [==============================] - 1505s 167ms/sample - loss: 0.6998 - accuracy: 0.7172 - val_loss: 0.9597 - val_accuracy: 0.6487\n",
      "Epoch 9/10\n",
      "9013/9013 [==============================] - 1511s 168ms/sample - loss: 0.6300 - accuracy: 0.7467 - val_loss: 0.8854 - val_accuracy: 0.6617\n",
      "Epoch 10/10\n",
      "9013/9013 [==============================] - 1520s 169ms/sample - loss: 0.6059 - accuracy: 0.7602 - val_loss: 0.7959 - val_accuracy: 0.6657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa398d0d890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "ori_model.fit(X, y, epochs=25, validation_split=0.1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d5119ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/owenpi/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./models/feature/assets\n"
     ]
    }
   ],
   "source": [
    "ori_model.save('./models/feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6690ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"./models/feature\")\n",
    "\n",
    "\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=loaded_model.inputs,\n",
    "    outputs=loaded_model.get_layer(name=\"feature_output\").output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09f93869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10015/10015 [00:06<00:00, 1610.32it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    sex = 0 if df.iloc[i]['sex'] == 'male' else 1\n",
    "    age = df.iloc[i]['age']\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array([sex, age])\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15)))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15)))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15)))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15)))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15)))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15)))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15)))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15)))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15)))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15)))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15)))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15)))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15)))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15)))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15)))\n",
    "\n",
    "    feature_vector.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "693d5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3013ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 17)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = feature_extractor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd43b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for img_feat, feat in zip(image_features, feature_vector):\n",
    "    X.append(np.concatenate((img_feat, feat)))\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94dcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0df2c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9013 samples, validate on 1002 samples\n",
      "Epoch 1/10\n",
      "9013/9013 [==============================] - 1395s 155ms/sample - loss: 0.8991 - accuracy: 0.6574 - val_loss: 1.8887 - val_accuracy: 0.2166\n",
      "Epoch 2/10\n",
      "9013/9013 [==============================] - 1399s 155ms/sample - loss: 0.7943 - accuracy: 0.6831 - val_loss: 7.8821 - val_accuracy: 0.6487\n",
      "Epoch 3/10\n",
      "9013/9013 [==============================] - 1506s 167ms/sample - loss: 0.7726 - accuracy: 0.6788 - val_loss: 0.8484 - val_accuracy: 0.6527\n",
      "Epoch 4/10\n",
      "9013/9013 [==============================] - 1506s 167ms/sample - loss: 0.7592 - accuracy: 0.6847 - val_loss: 2.2043 - val_accuracy: 0.6487\n",
      "Epoch 5/10\n",
      "9013/9013 [==============================] - 1505s 167ms/sample - loss: 0.7377 - accuracy: 0.6937 - val_loss: 4.0482 - val_accuracy: 0.6487\n",
      "Epoch 6/10\n",
      "9013/9013 [==============================] - 1505s 167ms/sample - loss: 0.7242 - accuracy: 0.7004 - val_loss: 1.0555 - val_accuracy: 0.6487\n",
      "Epoch 7/10\n",
      "9013/9013 [==============================] - 1505s 167ms/sample - loss: 0.6911 - accuracy: 0.7156 - val_loss: 0.8887 - val_accuracy: 0.6597\n",
      "Epoch 8/10\n",
      "9013/9013 [==============================] - 1505s 167ms/sample - loss: 0.6998 - accuracy: 0.7172 - val_loss: 0.9597 - val_accuracy: 0.6487\n",
      "Epoch 9/10\n",
      "9013/9013 [==============================] - 1511s 168ms/sample - loss: 0.6300 - accuracy: 0.7467 - val_loss: 0.8854 - val_accuracy: 0.6617\n",
      "Epoch 10/10\n",
      "9013/9013 [==============================] - 1520s 169ms/sample - loss: 0.6059 - accuracy: 0.7602 - val_loss: 0.7959 - val_accuracy: 0.6657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa398d0d890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=25, validation_split=0.1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5531c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b9605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34bbfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5003793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d2eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624320f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3db8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef986e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058b31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc58cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97de4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d5119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94970074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ea0efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179</td>\n",
       "      <td>HAM_0003081</td>\n",
       "      <td>ISIC_0033860</td>\n",
       "      <td>df</td>\n",
       "      <td>consensus</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3482</td>\n",
       "      <td>HAM_0004982</td>\n",
       "      <td>ISIC_0025192</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8596</td>\n",
       "      <td>HAM_0006342</td>\n",
       "      <td>ISIC_0024425</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2317</td>\n",
       "      <td>HAM_0000536</td>\n",
       "      <td>ISIC_0031844</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4710</td>\n",
       "      <td>HAM_0000334</td>\n",
       "      <td>ISIC_0026860</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_molemax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age     sex  \\\n",
       "0   1179  HAM_0003081  ISIC_0033860   df  consensus  45.0    male   \n",
       "1   3482  HAM_0004982  ISIC_0025192   nv  follow_up  35.0    male   \n",
       "2   8596  HAM_0006342  ISIC_0024425   nv      histo  40.0  female   \n",
       "3   2317  HAM_0000536  ISIC_0031844  mel      histo  45.0  female   \n",
       "4   4710  HAM_0000334  ISIC_0026860   nv  follow_up  35.0  female   \n",
       "\n",
       "      localization        dataset  \n",
       "0          abdomen   vidir_modern  \n",
       "1  upper extremity  vidir_molemax  \n",
       "2             face      rosendahl  \n",
       "3  lower extremity      rosendahl  \n",
       "4          abdomen  vidir_molemax  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e016944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179</td>\n",
       "      <td>HAM_0003081</td>\n",
       "      <td>ISIC_0033860</td>\n",
       "      <td>df</td>\n",
       "      <td>consensus</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3482</td>\n",
       "      <td>HAM_0004982</td>\n",
       "      <td>ISIC_0025192</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8596</td>\n",
       "      <td>HAM_0006342</td>\n",
       "      <td>ISIC_0024425</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2317</td>\n",
       "      <td>HAM_0000536</td>\n",
       "      <td>ISIC_0031844</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4710</td>\n",
       "      <td>HAM_0000334</td>\n",
       "      <td>ISIC_0026860</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>lo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age     sex  \\\n",
       "0   1179  HAM_0003081  ISIC_0033860   df  consensus  45.0    male   \n",
       "1   3482  HAM_0004982  ISIC_0025192   nv  follow_up  35.0    male   \n",
       "2   8596  HAM_0006342  ISIC_0024425   nv      histo  40.0  female   \n",
       "3   2317  HAM_0000536  ISIC_0031844  mel      histo  45.0  female   \n",
       "4   4710  HAM_0000334  ISIC_0026860   nv  follow_up  35.0  female   \n",
       "\n",
       "      localization        dataset risk  \n",
       "0          abdomen   vidir_modern   no  \n",
       "1  upper extremity  vidir_molemax   lo  \n",
       "2             face      rosendahl   lo  \n",
       "3  lower extremity      rosendahl   hi  \n",
       "4          abdomen  vidir_molemax   lo  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append('no')\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append('lo')\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append('md')\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append('hi')\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c3bb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179</td>\n",
       "      <td>HAM_0003081</td>\n",
       "      <td>ISIC_0033860.jpg</td>\n",
       "      <td>df</td>\n",
       "      <td>consensus</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3482</td>\n",
       "      <td>HAM_0004982</td>\n",
       "      <td>ISIC_0025192.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8596</td>\n",
       "      <td>HAM_0006342</td>\n",
       "      <td>ISIC_0024425.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2317</td>\n",
       "      <td>HAM_0000536</td>\n",
       "      <td>ISIC_0031844.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4710</td>\n",
       "      <td>HAM_0000334</td>\n",
       "      <td>ISIC_0026860.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>lo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id          image_id   dx    dx_type   age     sex  \\\n",
       "0   1179  HAM_0003081  ISIC_0033860.jpg   df  consensus  45.0    male   \n",
       "1   3482  HAM_0004982  ISIC_0025192.jpg   nv  follow_up  35.0    male   \n",
       "2   8596  HAM_0006342  ISIC_0024425.jpg   nv      histo  40.0  female   \n",
       "3   2317  HAM_0000536  ISIC_0031844.jpg  mel      histo  45.0  female   \n",
       "4   4710  HAM_0000334  ISIC_0026860.jpg   nv  follow_up  35.0  female   \n",
       "\n",
       "      localization        dataset risk  \n",
       "0          abdomen   vidir_modern   no  \n",
       "1  upper extremity  vidir_molemax   lo  \n",
       "2             face      rosendahl   lo  \n",
       "3  lower extremity      rosendahl   hi  \n",
       "4          abdomen  vidir_molemax   lo  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_id'] = df['image_id'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa8363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16\n",
    "VGG_load = VGG16(weights='imagenet')\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23d510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=90, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True, preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
    "    vertical_flip=True, validation_split=0.1, zoom_range=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52fa9b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lo    6705\n",
       "hi    1627\n",
       "no    1356\n",
       "md     327\n",
       "Name: risk, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05725d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hi': 0, 'lo': 1, 'md': 2, 'no': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='training').class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6abefdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2003 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hi': 0, 'lo': 1, 'md': 2, 'no': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='validation').class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd0dc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {'hi':1, 'lo':0.25, 'md':5, 'no':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e24778b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179</td>\n",
       "      <td>HAM_0003081</td>\n",
       "      <td>ISIC_0033860.jpg</td>\n",
       "      <td>df</td>\n",
       "      <td>consensus</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>no</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3482</td>\n",
       "      <td>HAM_0004982</td>\n",
       "      <td>ISIC_0025192.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>lo</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8596</td>\n",
       "      <td>HAM_0006342</td>\n",
       "      <td>ISIC_0024425.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>lo</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2317</td>\n",
       "      <td>HAM_0000536</td>\n",
       "      <td>ISIC_0031844.jpg</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>hi</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4710</td>\n",
       "      <td>HAM_0000334</td>\n",
       "      <td>ISIC_0026860.jpg</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>lo</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id          image_id   dx    dx_type   age     sex  \\\n",
       "0   1179  HAM_0003081  ISIC_0033860.jpg   df  consensus  45.0    male   \n",
       "1   3482  HAM_0004982  ISIC_0025192.jpg   nv  follow_up  35.0    male   \n",
       "2   8596  HAM_0006342  ISIC_0024425.jpg   nv      histo  40.0  female   \n",
       "3   2317  HAM_0000536  ISIC_0031844.jpg  mel      histo  45.0  female   \n",
       "4   4710  HAM_0000334  ISIC_0026860.jpg   nv  follow_up  35.0  female   \n",
       "\n",
       "      localization        dataset risk  weight  \n",
       "0          abdomen   vidir_modern   no    1.00  \n",
       "1  upper extremity  vidir_molemax   lo    0.25  \n",
       "2             face      rosendahl   lo    0.25  \n",
       "3  lower extremity      rosendahl   hi    1.00  \n",
       "4          abdomen  vidir_molemax   lo    0.25  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    sample_weights.append(class_weights[df.iloc[i]['risk']])\n",
    "    \n",
    "df['weight'] = sample_weights\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bd88d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 validated image filenames belonging to 4 classes.\n",
      "Found 2003 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-613ac1733c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                           \u001b[0mx_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'risk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                           subset='validation'),\n\u001b[0;32m---> 12\u001b[0;31m     epochs=50)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;31m# _standardize_user_data, use the _prepare_model_with_inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_ADAPTER_FOR_STANDARDIZE_USER_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0mtraining_v2_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_prepare_model_with_inputs\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_input_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_get_input_from_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_input_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0;34m\"\"\"Get elements from the iterator and verify the input shape and type.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   \u001b[0mnext_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   if (tensor_util.is_tensor(next_element) or\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x=data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images', weight_col='weight',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='training'),\n",
    "    validation_data=data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images', weight_col='weight',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='validation'),\n",
    "    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e98b9146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10015/10015 [00:06<00:00, 1620.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10015, 17)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    sex = 0 if df.iloc[i]['sex'] == 'male' else 1\n",
    "    age = df.iloc[i]['age']\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array([sex, age])\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15)))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15)))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15)))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15)))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15)))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15)))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15)))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15)))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15)))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15)))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15)))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15)))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15)))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15)))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15)))\n",
    "\n",
    "    feature_vector.append(feat)\n",
    "feature_vector = np.array(feature_vector)\n",
    "\n",
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3754eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=VGG_load.inputs,\n",
    "    outputs=VGG_load.layers[-4].output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat_vec = feature_vector[i]    \n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file, target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    img_feat = feature_extractor(img)\n",
    "\n",
    "    preprocessed.append(np.concatenate((img_feat, feat_vec)))\n",
    "    \n",
    "preprocessed = np.array(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "278f6681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohr = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    risk = df.iloc[i]['risk']\n",
    "    \n",
    "    if risk == 'no':\n",
    "        ohr.append(tf.one_hot(0, 4))\n",
    "    elif risk == 'lo':\n",
    "        ohr.append(tf.one_hot(1, 4))\n",
    "    elif risk == 'md':\n",
    "        ohr.append(tf.one_hot(2, 4))\n",
    "    elif risk == 'hi':\n",
    "        ohr.append(tf.one_hot(3, 4))\n",
    "        \n",
    "ohr = np.array(ohr)\n",
    "\n",
    "ohr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4262b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = models.Sequential()\n",
    "new_model.add(layers.Dense(4096, activation='relu'))\n",
    "new_model.add(layers.Dense(2048, activation='relu'))\n",
    "new_model.add(layers.Dense(512, activation='relu'))\n",
    "new_model.add(layers.Dense(128, activation='relu'))\n",
    "new_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e769b1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-6403f5b5ab08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "new_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "new_model.fit(preprocessed, ohr, sample_weight=np.array(df['weight']), epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd49433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
