{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6aee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import activations\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb0215",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_image = pickle.load(open('forest.sav', 'rb'))\n",
    "resnet = tf.keras.models.load_model('New_RES_Augmentated.h5', compile=False)\n",
    "VGG = tf.keras.models.load_model('New_VGG_Augmented.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d1d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/aug_HAM10000_Metadata')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1afcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e5e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].fillna(0)\n",
    "feature_vector = []\n",
    "y = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    sex = [0, 0]\n",
    "    if df.iloc[i]['sex'] == 'male':\n",
    "        sex = [1, 0]\n",
    "    elif df.iloc[i]['sex'] == 'female':\n",
    "        sex = [0, 1]\n",
    "    \n",
    "    age = df.iloc[i]['age']\n",
    "    y.append(df.iloc[i]['risk'])\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    sex.append(age)\n",
    "    feat = np.array(sex)\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 14)))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 14)))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 14)))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 14)))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 14)))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 14)))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 14)))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 14)))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 14)))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 14)))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 14)))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat, np.zeros(14)))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 14)))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 14)))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 14)))\n",
    "\n",
    "    feature_vector.append(feat)\n",
    "\n",
    "feat_X = np.array(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_preds = []\n",
    "\n",
    "VGG_load = VGG16(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat = feat_X[i]\n",
    "    \n",
    "    img = image.load_img('./data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(25088)\n",
    "    \n",
    "    vgg_preds.append(VGG.predict(preds.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c34293",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vgg_preds, open('vgg_preds', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c260e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_preds = []\n",
    "\n",
    "res_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(res_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, TOTAL)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat = feat_X[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "    \n",
    "    res_preds.append(resnet.predict(preds.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d48284",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vgg_preds, open('resnet_preds', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b131882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c917a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b97a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ae75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_preds = non_image.predict_proba(feat_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7659aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(non_preds, open('non_preds', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1311f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905eedc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92702da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62468dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(X):\n",
    "    p1 = X[0]\n",
    "    p2 = X[1]\n",
    "    p3 = 1 - X[0] - X[1]\n",
    "    predict = p1 * vgg_preds + p2 * resnet_preds + p3 * non_preds\n",
    "    \n",
    "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    return cce(y, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "varbound=np.array([[0,0.5]]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_param = {'max_num_iteration': 3000,\\\n",
    "                   'population_size':100,\\\n",
    "                   'mutation_probability':0.1,\\\n",
    "                   'elit_ratio': 0.01,\\\n",
    "                   'crossover_probability': 0.5,\\\n",
    "                   'parents_portion': 0.3,\\\n",
    "                   'crossover_type':'uniform',\\\n",
    "                   'max_iteration_without_improv':None}\n",
    "\n",
    "\n",
    "model=ga(function=fitness,\n",
    "         dimension=2,\n",
    "         variable_type='real',\n",
    "         variable_boundaries=varbound,\n",
    "         algorithm_parameters=algorithm_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03374f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bed91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
