{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bfb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import activations\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea71cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ab63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unagumented\n",
    "df = pd.read_csv('./Unaug_Data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b898f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9e43e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  risk  \n",
       "0  vidir_modern   0.0  \n",
       "1  vidir_modern   0.0  \n",
       "2  vidir_modern   0.0  \n",
       "3  vidir_modern   0.0  \n",
       "4  vidir_modern   0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unagumented\n",
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22543c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    6705\n",
       "3.0    1627\n",
       "0.0    1356\n",
       "2.0     327\n",
       "Name: risk, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7903074",
   "metadata": {},
   "source": [
    "# Separate Data into Even Baskets and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68186b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df0 = df.loc[df[\"risk\"] == 0]\n",
    "df1 = df.loc[df[\"risk\"] == 1] \n",
    "df2 = df.loc[df[\"risk\"] == 2] \n",
    "df3 = df.loc[df[\"risk\"] == 3] \n",
    "\n",
    "#Randomly Shuffle rows\n",
    "df0 = df0.sample(frac = 1).reset_index(drop = True)\n",
    "df1 = df1.sample(frac = 1).reset_index(drop = True)\n",
    "df2 = df2.sample(frac = 1).reset_index(drop = True)\n",
    "df3 = df3.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98e6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Training and Testing Dataset; select last 20 elements from each class as testing dataframe\n",
    "test_df = df0.iloc[-20:, :]\n",
    "test_df = test_df.append(df1.iloc[-20:,:])\n",
    "test_df = test_df.append(df2.iloc[-20:, :])\n",
    "test_df = test_df.append(df3.iloc[-20:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f9130d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop last 20 elements from training dataframe\n",
    "df0 = df0.iloc[:-20,:]\n",
    "df1 = df1.iloc[:-20,:]\n",
    "df2 = df2.iloc[:-20,:]\n",
    "df3 = df3.iloc[:-20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe00c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1088e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc3512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0321e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 265\n",
    "basket = 1\n",
    "start = 0\n",
    "total_df = df0.iloc[start: basket*count,:]\n",
    "while basket < 6:\n",
    "    total_df = total_df.append(df1.iloc[start:basket*count, :], ignore_index = True)\n",
    "    total_df = total_df.append(df2.iloc[0:265, :], ignore_index = True)\n",
    "    total_df = total_df.append(df3.iloc[start:basket*count, :], ignore_index = True)\n",
    "    basket = basket + 1\n",
    "    start += 265\n",
    "    total_df = total_df.append(df0.iloc[start:basket*count, :], ignore_index = True)\n",
    "total_df = total_df.iloc[:-11, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7934a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff368611",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca8f484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2ed74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a67f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "decf618d",
   "metadata": {},
   "source": [
    "# Preprocessing and Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f70ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.001,\n",
    "  patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c0ee3",
   "metadata": {},
   "source": [
    "## Separate input and output into five fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4d8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basket = 1060\n",
    "df1 = total_df.iloc[0:Basket, :]\n",
    "df2 = total_df.iloc[Basket:2*Basket, :]\n",
    "df3 = total_df.iloc[2*Basket: 3*Basket, :]\n",
    "df4 = total_df.iloc[3*Basket:4*Basket, :]\n",
    "df5 = total_df.iloc[4*Basket:5*Basket, :]\n",
    "\n",
    "df1 = df1.sample(frac = 1).reset_index(drop = True)\n",
    "df2= df2.sample(frac = 1).reset_index(drop = True)\n",
    "df3 = df3.sample(frac = 1).reset_index(drop = True)\n",
    "df4 = df4.sample(frac = 1).reset_index(drop = True)\n",
    "df5 = df5.sample(frac = 1).reset_index(drop = True)\n",
    "test_df = test_df.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb5eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VAL = 80\n",
    "NUM_TRN = 1060\n",
    "TOTAL = 1060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16f02fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0002011</td>\n",
       "      <td>ISIC_0031711</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0004883</td>\n",
       "      <td>ISIC_0031851</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0004746</td>\n",
       "      <td>ISIC_0029021</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0004397</td>\n",
       "      <td>ISIC_0025589</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>neck</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0005154</td>\n",
       "      <td>ISIC_0024762</td>\n",
       "      <td>nv</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>HAM_0003144</td>\n",
       "      <td>ISIC_0032135</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>HAM_0003001</td>\n",
       "      <td>ISIC_0032514</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>HAM_0003025</td>\n",
       "      <td>ISIC_0027440</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>HAM_0004472</td>\n",
       "      <td>ISIC_0025368</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>HAM_0004224</td>\n",
       "      <td>ISIC_0027194</td>\n",
       "      <td>bkl</td>\n",
       "      <td>confocal</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id      image_id     dx    dx_type   age     sex  \\\n",
       "0   HAM_0002011  ISIC_0031711    mel      histo  55.0  female   \n",
       "1   HAM_0004883  ISIC_0031851    bkl      histo  55.0    male   \n",
       "2   HAM_0004746  ISIC_0029021    mel      histo  65.0  female   \n",
       "3   HAM_0004397  ISIC_0025589    mel      histo  55.0  female   \n",
       "4   HAM_0005154  ISIC_0024762     nv  consensus  55.0    male   \n",
       "..          ...           ...    ...        ...   ...     ...   \n",
       "75  HAM_0003144  ISIC_0032135  akiec      histo  65.0  female   \n",
       "76  HAM_0003001  ISIC_0032514    bkl      histo  75.0    male   \n",
       "77  HAM_0003025  ISIC_0027440     nv  follow_up  35.0  female   \n",
       "78  HAM_0004472  ISIC_0025368  akiec      histo  40.0  female   \n",
       "79  HAM_0004224  ISIC_0027194    bkl   confocal  80.0    male   \n",
       "\n",
       "       localization        dataset  risk  \n",
       "0   lower extremity   vidir_modern   3.0  \n",
       "1              back      rosendahl   0.0  \n",
       "2              back      rosendahl   3.0  \n",
       "3              neck   vidir_modern   3.0  \n",
       "4              back   vidir_modern   1.0  \n",
       "..              ...            ...   ...  \n",
       "75             face      rosendahl   2.0  \n",
       "76             face   vidir_modern   0.0  \n",
       "77            trunk  vidir_molemax   1.0  \n",
       "78             face      rosendahl   2.0  \n",
       "79             face   vidir_modern   0.0  \n",
       "\n",
       "[80 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da68614d",
   "metadata": {},
   "source": [
    "## VGG Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccef647",
   "metadata": {},
   "source": [
    "### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38191d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:08<00:00,  9.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 80)):\n",
    "    file = test_df.iloc[i]['image_id']\n",
    "    #feat = feat_X[i]\n",
    "    \n",
    "    #img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.load_img('./Unaug_Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(preds)#np.concatenate((preds, feat)))\n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "VGG_X = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57bd991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_X_val = np.array(VGG_X)\n",
    "del VGG_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "040e69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.array(test_df['risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c13cd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "for ele in test_df['risk']:\n",
    "    risk.append(tf.one_hot(int(ele),4))\n",
    "y_val = np.array(risk)\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce571a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b39b15a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_val = []\n",
    "for ele in y_val:\n",
    "    new_y_val.append(ele)\n",
    "    \n",
    "new_y_val = np.array(new_y_val)\n",
    "\n",
    "new_y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65b4bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 17786.61it/s]\n"
     ]
    }
   ],
   "source": [
    "new_VGG_val = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    new_VGG_val.append(np.array(VGG_X_val[i]))\n",
    "\n",
    "new_VGG_val = np.array(new_VGG_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9e0418b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 0., 3., 3., 1., 0., 1., 0., 0., 3., 0., 3., 3., 2., 3., 2., 2.,\n",
       "       2., 3., 2., 1., 2., 0., 1., 1., 1., 3., 3., 3., 1., 2., 2., 3., 1.,\n",
       "       0., 3., 2., 2., 1., 2., 0., 1., 3., 0., 0., 0., 3., 1., 2., 0., 0.,\n",
       "       1., 2., 1., 2., 3., 2., 1., 3., 1., 1., 3., 1., 0., 0., 2., 3., 0.,\n",
       "       3., 0., 2., 1., 0., 2., 1., 2., 0., 1., 2., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22857098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dd3cd51",
   "metadata": {},
   "source": [
    "### Basket 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a7e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1060/1060 [01:02<00:00, 16.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 1060)):\n",
    "    file = df1.iloc[i]['image_id']\n",
    "    #feat = feat_X[i]\n",
    "    \n",
    "    #img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.load_img('./Unaug_Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(preds)#np.concatenate((preds, feat)))\n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "VGG_X = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03a5b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn = np.array(df1['risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7278581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_X_trn = np.array(VGG_X)\n",
    "\n",
    "del VGG_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23b98853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_trn = []\n",
    "for ele in y_trn:\n",
    "    new_y_trn.append(ele)\n",
    "    \n",
    "new_y_trn = np.array(new_y_trn)\n",
    "\n",
    "new_y_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "713d66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1060/1060 [00:00<00:00, 8783.73it/s]\n"
     ]
    }
   ],
   "source": [
    "new_VGG_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    new_VGG_trn.append(np.array(VGG_X_trn[i]))\n",
    "\n",
    "new_VGG_trn = np.array(new_VGG_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df877ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060, 100352)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_VGG_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "647cd2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model1 = models.Sequential()\n",
    "#vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "vgg_model1.add(layers.Dense(2048, activation='tanh'))\n",
    "vgg_model1.add(layers.BatchNormalization())\n",
    "vgg_model1.add(layers.Dense(1024, activation='tanh'))\n",
    "vgg_model1.add(layers.BatchNormalization())\n",
    "vgg_model1.add(layers.Dense(512, activation='tanh'))\n",
    "vgg_model1.add(layers.BatchNormalization())\n",
    "vgg_model1.add(layers.Dense(128, activation='tanh'))\n",
    "vgg_model1.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5634a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c4cb4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "133/133 [==============================] - 3s 18ms/step - loss: 10.0080 - accuracy: 0.2566 - val_loss: 9.6648 - val_accuracy: 0.2250\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 9.5933 - accuracy: 0.2377 - val_loss: 9.9108 - val_accuracy: 0.2000\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 9.3716 - accuracy: 0.2311 - val_loss: 9.6556 - val_accuracy: 0.2875\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 9.2732 - accuracy: 0.2481 - val_loss: 9.7763 - val_accuracy: 0.2375\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 9.1672 - accuracy: 0.2151 - val_loss: 9.6425 - val_accuracy: 0.2625\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 9.0951 - accuracy: 0.2160 - val_loss: 9.5152 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145e3b85d00>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000005),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "vgg_model1.fit(new_VGG_trn, new_y_trn, \n",
    "              epochs=10, \n",
    "              validation_data=(new_VGG_val, new_y_val),\n",
    "              batch_size = 8,\n",
    "              callbacks=[earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64dc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vgg model\n",
    "vgg_model1.save(\"VGG_P1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fef76f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_y_vgg_val_1 = []\n",
    "#temp_vgg_trn = vgg_model.predict(new_VGG_trn)\n",
    "temp_vgg_val_1 = vgg_model1.predict(new_VGG_val)\n",
    "\n",
    "#del new_VGG_trn\n",
    "#del new_VGG_val\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_vgg_val_1[i])\n",
    "    predict_y_vgg_val_1.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a438577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_vgg_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73082228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 0., 3., 3., 1., 0., 1., 0., 0., 3., 0., 3., 3., 2., 3., 2., 2.,\n",
       "       2., 3., 2., 1., 2., 0., 1., 1., 1., 3., 3., 3., 1., 2., 2., 3., 1.,\n",
       "       0., 3., 2., 2., 1., 2., 0., 1., 3., 0., 0., 0., 3., 1., 2., 0., 0.,\n",
       "       1., 2., 1., 2., 3., 2., 1., 3., 1., 1., 3., 1., 0., 0., 2., 3., 0.,\n",
       "       3., 0., 2., 1., 0., 2., 1., 2., 0., 1., 2., 0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed494be",
   "metadata": {},
   "source": [
    "### Basket 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c42448b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1060/1060 [01:03<00:00, 16.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 1060)):\n",
    "    file = df2.iloc[i]['image_id']\n",
    "    #feat = feat_X[i]\n",
    "    \n",
    "    #img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.load_img('./Unaug_Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(preds)#np.concatenate((preds, feat)))\n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "VGG_X = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2017891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1060/1060 [00:00<00:00, 7085.54it/s]\n"
     ]
    }
   ],
   "source": [
    "y_trn = np.array(df2['risk'])\n",
    "\n",
    "\n",
    "VGG_X_trn = np.array(VGG_X)\n",
    "\n",
    "\n",
    "del VGG_X\n",
    "\n",
    "\n",
    "\n",
    "new_y_trn = []\n",
    "for ele in y_trn:\n",
    "    new_y_trn.append(ele)\n",
    "    \n",
    "new_y_trn = np.array(new_y_trn)\n",
    "\n",
    "\n",
    "new_VGG_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    new_VGG_trn.append(np.array(VGG_X_trn[i]))\n",
    "\n",
    "new_VGG_trn = np.array(new_VGG_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee0b15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "133/133 [==============================] - 3s 19ms/step - loss: 10.3834 - accuracy: 0.2491 - val_loss: 9.3716 - val_accuracy: 0.3000\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 9.4722 - accuracy: 0.2594 - val_loss: 10.1210 - val_accuracy: 0.2750\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 9.0948 - accuracy: 0.2472 - val_loss: 9.1054 - val_accuracy: 0.2125\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 8.8596 - accuracy: 0.2632 - val_loss: 9.4624 - val_accuracy: 0.2750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145d0b87400>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model2 = models.Sequential()\n",
    "\n",
    "#vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "vgg_model2.add(layers.Dense(2048, activation='tanh'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model2.add(layers.Dense(1024, activation='tanh'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model2.add(layers.Dense(512, activation='tanh'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model2.add(layers.Dense(128, activation='tanh'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model2.add(layers.Dense(4))\n",
    "\n",
    "vgg_model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "vgg_model2.fit(new_VGG_trn, new_y_trn, \n",
    "              epochs=30, \n",
    "              validation_data=(new_VGG_val, new_y_val),\n",
    "              batch_size = 8,\n",
    "              callbacks=[earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dab5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vgg model\n",
    "vgg_model2.save(\"VGG_P2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71c73dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_y_vgg_val_2 = []\n",
    "#temp_vgg_trn = vgg_model.predict(new_VGG_trn)\n",
    "temp_vgg_val_2 = vgg_model2.predict(new_VGG_val)\n",
    "\n",
    "#del new_VGG_trn\n",
    "#del new_VGG_val\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_vgg_val_2[i])\n",
    "    predict_y_vgg_val_2.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afc1f03b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_vgg_val_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b4cae",
   "metadata": {},
   "source": [
    "### Basket 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20fb832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1060 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 1070 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000145BC83FAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1060/1060 [01:00<00:00, 17.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 1060)):\n",
    "    file = df3.iloc[i]['image_id']\n",
    "    #feat = feat_X[i]\n",
    "    \n",
    "    #img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.load_img('./Unaug_Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(preds)#np.concatenate((preds, feat)))\n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "VGG_X = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd70b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1060/1060 [00:00<00:00, 8856.94it/s]\n"
     ]
    }
   ],
   "source": [
    "y_trn = np.array(df3['risk'])\n",
    "\n",
    "\n",
    "VGG_X_trn = np.array(VGG_X)\n",
    "\n",
    "\n",
    "del VGG_X\n",
    "\n",
    "\n",
    "\n",
    "new_y_trn = []\n",
    "for ele in y_trn:\n",
    "    new_y_trn.append(ele)\n",
    "    \n",
    "new_y_trn = np.array(new_y_trn)\n",
    "\n",
    "\n",
    "new_VGG_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    new_VGG_trn.append(np.array(VGG_X_trn[i]))\n",
    "\n",
    "new_VGG_trn = np.array(new_VGG_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a66086ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 11.0549 - accuracy: 0.2698 - val_loss: 10.0212 - val_accuracy: 0.2375\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 17.6872 - accuracy: 0.2594 - val_loss: 36.2834 - val_accuracy: 0.2625\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 99.5561 - accuracy: 0.2594 - val_loss: 264.2057 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 685.0918 - accuracy: 0.2547 - val_loss: 1963.3142 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 1499.3347 - accuracy: 0.2538 - val_loss: 1346.1414 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14543552dc0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model3 = models.Sequential()\n",
    "#vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "vgg_model3.add(layers.Dense(2048, activation='relu'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model3.add(layers.Dense(1024, activation='relu'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model3.add(layers.Dense(512, activation='relu'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model3.add(layers.Dense(128, activation='relu'))\n",
    "vgg_model3.add(layers.Dense(4))\n",
    "\n",
    "vgg_model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "vgg_model3.fit(new_VGG_trn, new_y_trn, \n",
    "              epochs=30, \n",
    "              validation_data=(new_VGG_val, new_y_val), \n",
    "              callbacks=[earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vgg model\n",
    "vgg_model3.save(\"VGG_P3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e7a9c1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 80216.19it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_y_vgg_val_3 = []\n",
    "#temp_vgg_trn = vgg_model.predict(new_VGG_trn)\n",
    "temp_vgg_val_3 = vgg_model3.predict(new_VGG_val)\n",
    "\n",
    "#del new_VGG_trn\n",
    "#del new_VGG_val\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_vgg_val_3[i])\n",
    "    predict_y_vgg_val_3.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6811aba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_vgg_val_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3373f73",
   "metadata": {},
   "source": [
    "### Basket 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d86318c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1060 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 1070 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000014536A405E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1060/1060 [01:02<00:00, 16.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 1060)):\n",
    "    file = df4.iloc[i]['image_id']\n",
    "    #feat = feat_X[i]\n",
    "    \n",
    "    #img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.load_img('./Unaug_Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(preds)#np.concatenate((preds, feat)))\n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "VGG_X = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42c3b145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1060/1060 [00:00<00:00, 7564.35it/s]\n"
     ]
    }
   ],
   "source": [
    "y_trn = np.array(df4['risk'])\n",
    "\n",
    "\n",
    "VGG_X_trn = np.array(VGG_X)\n",
    "\n",
    "\n",
    "del VGG_X\n",
    "\n",
    "\n",
    "\n",
    "new_y_trn = []\n",
    "for ele in y_trn:\n",
    "    new_y_trn.append(ele)\n",
    "    \n",
    "new_y_trn = np.array(new_y_trn)\n",
    "\n",
    "\n",
    "new_VGG_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    new_VGG_trn.append(np.array(VGG_X_trn[i]))\n",
    "\n",
    "new_VGG_trn = np.array(new_VGG_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7deb5065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:858 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:847 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3652 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:840 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:792 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\sequential.py:383 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1030 __call__\n        self._maybe_build(inputs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:2659 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\core.py:1178 build\n        self.kernel = self.add_weight(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:647 add_weight\n        variable = self._add_variable_with_custom_getter(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:813 _add_variable_with_custom_getter\n        new_variable = getter(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:117 make_variable\n        return tf.compat.v1.Variable(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:266 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:212 _variable_v1_call\n        return previous_getter(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3567 creator\n        return next_creator(**kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3567 creator\n        return next_creator(**kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3567 creator\n        return next_creator(**kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:746 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:270 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:294 __init__\n        initial_value = initial_value()\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:517 __call__\n        return self._random_generator.random_uniform(shape, -limit, limit, dtype)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:972 random_uniform\n        return op(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py:315 random_uniform\n        result = math_ops.add(result * (maxval - minval), minval, name=name)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3943 add\n        return gen_math_ops.add_v2(x, y, name=name)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:454 add_v2\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7023 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: failed to allocate memory [Op:AddV2]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-bab8bdc20b37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m---> 16\u001b[1;33m vgg_model4.fit(new_VGG_trn, new_y_trn, \n\u001b[0m\u001b[0;32m     17\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_VGG_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_y_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 _r=1):\n\u001b[0;32m   1188\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: in user code:\n\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:858 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:847 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3652 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:840 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:792 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\sequential.py:383 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1030 __call__\n        self._maybe_build(inputs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:2659 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\core.py:1178 build\n        self.kernel = self.add_weight(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:647 add_weight\n        variable = self._add_variable_with_custom_getter(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:813 _add_variable_with_custom_getter\n        new_variable = getter(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:117 make_variable\n        return tf.compat.v1.Variable(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:266 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:212 _variable_v1_call\n        return previous_getter(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3567 creator\n        return next_creator(**kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3567 creator\n        return next_creator(**kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3567 creator\n        return next_creator(**kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:746 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:270 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:294 __init__\n        initial_value = initial_value()\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:517 __call__\n        return self._random_generator.random_uniform(shape, -limit, limit, dtype)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:972 random_uniform\n        return op(\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py:315 random_uniform\n        result = math_ops.add(result * (maxval - minval), minval, name=name)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3943 add\n        return gen_math_ops.add_v2(x, y, name=name)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:454 add_v2\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\15521\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7023 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: failed to allocate memory [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "vgg_model4 = models.Sequential()\n",
    "#vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "vgg_model4.add(layers.Dense(2048, activation='relu'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model4.add(layers.Dense(1024, activation='relu'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model4.add(layers.Dense(512, activation='relu'))\n",
    "vgg_model2.add(layers.BatchNormalization())\n",
    "vgg_model4.add(layers.Dense(128, activation='relu'))\n",
    "vgg_model4.add(layers.Dense(4))\n",
    "\n",
    "vgg_model4.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "vgg_model4.fit(new_VGG_trn, new_y_trn, \n",
    "              epochs=30, \n",
    "              validation_data=(new_VGG_val, new_y_val), \n",
    "              callbacks=[earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vgg model\n",
    "vgg_model4.save(\"VGG_P4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0cdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_vgg_val_4 = []\n",
    "#temp_vgg_trn = vgg_model.predict(new_VGG_trn)\n",
    "temp_vgg_val_4 = vgg_model4.predict(new_VGG_val)\n",
    "\n",
    "#del new_VGG_trn\n",
    "#del new_VGG_val\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_vgg_val_4[i])\n",
    "    predict_y_vgg_val_4.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd0551",
   "metadata": {},
   "source": [
    "### Basket 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 1060)):\n",
    "    file = df5.iloc[i]['image_id']\n",
    "    #feat = feat_X[i]\n",
    "    \n",
    "    #img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.load_img('./Unaug_Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(preds)#np.concatenate((preds, feat)))\n",
    "'''mx = 0\n",
    "for i in range(0, TOTAL):\n",
    "    if mx < np.amax(preprocessed[i]):\n",
    "        mx = np.amax(preprocessed[i])\n",
    "\n",
    "preprocessed = list(preprocessed / mx)\n",
    "'''\n",
    "VGG_X = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4287aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn = np.array(df5['risk'])\n",
    "\n",
    "\n",
    "VGG_X_trn = np.array(VGG_X)\n",
    "\n",
    "\n",
    "del VGG_X\n",
    "\n",
    "\n",
    "\n",
    "new_y_trn = []\n",
    "for ele in y_trn:\n",
    "    new_y_trn.append(ele)\n",
    "    \n",
    "new_y_trn = np.array(new_y_trn)\n",
    "\n",
    "\n",
    "new_VGG_trn = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_TRN)):\n",
    "    new_VGG_trn.append(np.array(VGG_X_trn[i]))\n",
    "\n",
    "new_VGG_trn = np.array(new_VGG_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21963eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model5 = models.Sequential()\n",
    "#vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "vgg_model5.add(layers.Dense(2048, activation='relu'))\n",
    "vgg_model5.add(layers.Dense(1024, activation='relu'))\n",
    "vgg_model5.add(layers.Dense(512, activation='relu'))\n",
    "vgg_model5.add(layers.Dense(128, activation='relu'))\n",
    "vgg_model5.add(layers.Dense(4))\n",
    "\n",
    "vgg_model5.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "vgg_model5.fit(new_VGG_trn, new_y_trn, \n",
    "              epochs=30, \n",
    "              validation_data=(new_VGG_val, new_y_val), \n",
    "              callbacks=[earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save vgg model\n",
    "vgg_model5.save(\"VGG_P5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_vgg_val_5 = []\n",
    "#temp_vgg_trn = vgg_model.predict(new_VGG_trn)\n",
    "temp_vgg_val_5 = vgg_model5.predict(new_VGG_val)\n",
    "\n",
    "#del new_VGG_trn\n",
    "#del new_VGG_val\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_vgg_val_5[i])\n",
    "    predict_y_vgg_val_5.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2252aa4",
   "metadata": {},
   "source": [
    "# Ensemble Five Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6e3c7",
   "metadata": {},
   "source": [
    "### Average Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c7018ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_all = []\n",
    "for i in range(0, NUM_VAL):\n",
    "    temp_all.append((temp_vgg_val_1[i]+temp_vgg_val_2[i]+temp_vgg_val_3[i])/3)#+temp_vgg_val_4[i]+temp_vgg_val_5[i]))\n",
    "temp_all = np.array(temp_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ac1ee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_y_final_val = []\n",
    "\n",
    "for i in tqdm(range(0, NUM_VAL)):\n",
    "    pred = np.argmax(temp_all[i])\n",
    "    predict_y_final_val.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9646e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_final = tf.math.confusion_matrix(np.array(test_df['risk']), np.array(predict_y_final_val))\n",
    "\n",
    "cm_final = np.array(cm_final).astype('float32')\n",
    "\n",
    "cm_final[0] = cm_final[0] / (1.0 * cm_final[0].sum())\n",
    "cm_final[1] = cm_final[1] / (1.0 * cm_final[1].sum())\n",
    "cm_final[2] = cm_final[2] / (1.0 * cm_final[2].sum())\n",
    "cm_final[3] = cm_final[3] / (1.0 * cm_final[3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f60dabbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = sns.heatmap(cm_final, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb211349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final pic\n",
    "figure = svm.get_figure()\n",
    "figure.savefig(r\"A:\\Deep Learning\\Term Project\\Pic\\Ensemble-Resnet-no adjustment\\final.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67ae66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_y_vgg_val_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "546b1f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model1 = tf.math.confusion_matrix(np.array(test_df['risk']), np.array(predict_y_vgg_val_1))\n",
    "cm_model1 = np.array(cm_model1).astype('float32')\n",
    "\n",
    "cm_model2 = tf.math.confusion_matrix(np.array(test_df['risk']), np.array(predict_y_vgg_val_2))\n",
    "cm_model2 = np.array(cm_model2).astype('float32')\n",
    "\n",
    "cm_model3 = tf.math.confusion_matrix(np.array(test_df['risk']), np.array(predict_y_vgg_val_3))\n",
    "cm_model3 = np.array(cm_model3).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb2aca36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a99a7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model1[0] = cm_model1[0] / (1.0 * cm_model1[0].sum())\n",
    "cm_model1[1] = cm_model1[1] / (1.0 * cm_model1[1].sum())\n",
    "cm_model1[2] = cm_model1[2] / (1.0 * cm_model1[2].sum())\n",
    "cm_model1[3] = cm_model1[3] / (1.0 * cm_model1[3].sum())\n",
    "\n",
    "cm_model2[0] = cm_model2[0] / (1.0 * cm_model2[0].sum())\n",
    "cm_model2[1] = cm_model2[1] / (1.0 * cm_model2[1].sum())\n",
    "cm_model2[2] = cm_model2[2] / (1.0 * cm_model2[2].sum())\n",
    "cm_model2[3] = cm_model2[3] / (1.0 * cm_model2[3].sum())\n",
    "\n",
    "cm_model3[0] = cm_model3[0] / (1.0 * cm_model3[0].sum())\n",
    "cm_model3[1] = cm_model3[1] / (1.0 * cm_model3[1].sum())\n",
    "cm_model3[2] = cm_model3[2] / (1.0 * cm_model3[2].sum())\n",
    "cm_model3[3] = cm_model3[3] / (1.0 * cm_model3[3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9bc50cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm1 = sns.heatmap(cm_model1, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d6c32aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm2 = sns.heatmap(cm_model2, annot=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3623992f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm3 = sns.heatmap(cm_model3, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "22ac2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1 = svm1.get_figure()\n",
    "figure1.savefig(r\"A:\\Deep Learning\\Term Project\\Pic\\Ensemble-Resnet-no adjustment\\model1.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c37cba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure2 = svm2.get_figure()\n",
    "figure2.savefig(r\"A:\\Deep Learning\\Term Project\\Pic\\Ensemble-Resnet-no adjustment\\model2.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2800caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure3 = svm3.get_figure()\n",
    "figure3.savefig(r\"A:\\Deep Learning\\Term Project\\Pic\\Ensemble-Resnet-no adjustment\\model3.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c16ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow gpu",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
