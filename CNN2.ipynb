{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9c9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import activations\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82de03f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddfe42",
   "metadata": {},
   "source": [
    "(Warning for Sunlight, increased risk of cancer) Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "(Skin cancer) basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "(HARMLESS) benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "(HARMLESS) dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "(Not entirely harmless) melanocytic nevi (__nv__)   5\n",
    "\n",
    "(HARMLESS) vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cases where we can use LSTM\n",
    "\n",
    "(df['lesion_id'].value_counts() > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544945c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89856d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3064aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['localization'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    loc = df.iloc[i]['localization']\n",
    "    if loc == 'abdomen':\n",
    "        temp.append(tf.one_hot(0, 15))\n",
    "    elif loc == 'scalp':\n",
    "        temp.append(tf.one_hot(1, 15))\n",
    "    elif loc == 'lower extremity':\n",
    "        temp.append(tf.one_hot(2, 15))\n",
    "    elif loc == 'trunk':\n",
    "        temp.append(tf.one_hot(3, 15))\n",
    "    elif loc == 'upper extremity':\n",
    "        temp.append(tf.one_hot(4, 15))\n",
    "    elif loc == 'back':\n",
    "        temp.append(tf.one_hot(5, 15))\n",
    "    elif loc == 'neck':\n",
    "        temp.append(tf.one_hot(6, 15))\n",
    "    elif loc == 'face':\n",
    "        temp.append(tf.one_hot(7, 15))\n",
    "    elif loc == 'chest':\n",
    "        temp.append(tf.one_hot(8, 15))\n",
    "    elif loc == 'foot':\n",
    "        temp.append(tf.one_hot(9, 15))\n",
    "    elif loc == 'ear':\n",
    "        temp.append(tf.one_hot(10, 15))\n",
    "    elif loc == 'unknown':\n",
    "        temp.append(tf.one_hot(11, 15))\n",
    "    elif loc == 'hand':\n",
    "        temp.append(tf.one_hot(12, 15))\n",
    "    elif loc == 'acral':\n",
    "        temp.append(tf.one_hot(13, 15))\n",
    "    elif loc == 'genital':\n",
    "        temp.append(tf.one_hot(14, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_loc = np.array(temp)\n",
    "\n",
    "one_hot_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "VGG_load = VGG16(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    ohl = one_hot_loc[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(25088)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['VGG16'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88325339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception\n",
    "preprocessed = []\n",
    "\n",
    "IV3_load = InceptionV3(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(IV3_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    ohl = one_hot_loc[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(131072)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['IV3'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0493b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    ohl = one_hot_loc[i]    \n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['resnet'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff649448",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(0, 10015):\n",
    "    dx = df.iloc[i]['dx']\n",
    "    if dx == 'akiec':\n",
    "        labels.append(tf.one_hot(0, 7))\n",
    "    elif dx == 'bcc':\n",
    "        labels.append(tf.one_hot(1, 7))\n",
    "    elif dx == 'bkl':\n",
    "        labels.append(tf.one_hot(2, 7))\n",
    "    elif dx == 'df':\n",
    "        labels.append(tf.one_hot(3, 7))\n",
    "    elif dx == 'mel':\n",
    "        labels.append(tf.one_hot(4, 7))\n",
    "    elif dx == 'nv':\n",
    "        labels.append(tf.one_hot(5, 7))\n",
    "    elif dx == 'vasc':\n",
    "        labels.append(tf.one_hot(6, 7))\n",
    "        \n",
    "df['one_hot'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21be79",
   "metadata": {},
   "source": [
    "(Warning for Sunlight, increased risk of cancer) Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "(Skin cancer) basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "(HARMLESS) benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "(HARMLESS) dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "(Not entirely harmless) melanocytic nevi (__nv__)   5\n",
    "\n",
    "(HARMLESS) vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['risk'] == 3.0]['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_X = np.array(df['VGG16'])\n",
    "IV3_X = np.array(df['IV3'])\n",
    "RES_X = np.array(df['resnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = np.array(df['one_hot'])\n",
    "\n",
    "y = np.array(df['risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = models.Sequential()\n",
    "vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "vgg_model.add(layers.Dense(2048, activation='relu'))\n",
    "vgg_model.add(layers.Dense(1024, activation='relu'))\n",
    "vgg_model.add(layers.Dense(512, activation='relu'))\n",
    "vgg_model.add(layers.Dense(128, activation='relu'))\n",
    "vgg_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3316d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_VGG = np.asarray(new_VGG).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_VGG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c802b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = []\n",
    "for ele in y:\n",
    "    new_y.append(np.array(ele))\n",
    "    \n",
    "new_y = np.array(new_y)\n",
    "\n",
    "new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5801ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(new_VGG, new_y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = models.Sequential()\n",
    "res_model.add(layers.Dense(8192, activation='relu'))\n",
    "res_model.add(layers.Dense(4096, activation='relu'))\n",
    "res_model.add(layers.Dense(2048, activation='relu'))\n",
    "res_model.add(layers.Dense(1024, activation='relu'))\n",
    "res_model.add(layers.Dense(512, activation='relu'))\n",
    "res_model.add(layers.Dense(128, activation='relu'))\n",
    "res_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "res_model.fit(new_RES, new_y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model = models.Sequential()\n",
    "iv3_model.add(layers.Dense(8192, activation='relu'))\n",
    "iv3_model.add(layers.Dense(4096, activation='relu'))\n",
    "iv3_model.add(layers.Dense(2048, activation='relu'))\n",
    "iv3_model.add(layers.Dense(1024, activation='relu'))\n",
    "iv3_model.add(layers.Dense(512, activation='relu'))\n",
    "iv3_model.add(layers.Dense(128, activation='relu'))\n",
    "iv3_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "iv3_model.fit(new_IV3, new_y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bbb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccae92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026d0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e74929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e7b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1abaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d437e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf377c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dda89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637dbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506a501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed4d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45456df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d40466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12ec97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b141d78b",
   "metadata": {},
   "source": [
    "# New Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c427cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b0abda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161</td>\n",
       "      <td>HAM_0005386</td>\n",
       "      <td>ISIC_0033973</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6143</td>\n",
       "      <td>HAM_0005593</td>\n",
       "      <td>ISIC_0029658</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_molemax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2738</td>\n",
       "      <td>HAM_0005757</td>\n",
       "      <td>ISIC_0026496</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9515</td>\n",
       "      <td>HAM_0005115</td>\n",
       "      <td>ISIC_0033766</td>\n",
       "      <td>nv</td>\n",
       "      <td>consensus</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1257</td>\n",
       "      <td>HAM_0004720</td>\n",
       "      <td>ISIC_0027277</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age   sex  \\\n",
       "0    161  HAM_0005386  ISIC_0033973  bkl      histo  45.0  male   \n",
       "1   6143  HAM_0005593  ISIC_0029658   nv  follow_up  45.0  male   \n",
       "2   2738  HAM_0005757  ISIC_0026496  bcc      histo  70.0  male   \n",
       "3   9515  HAM_0005115  ISIC_0033766   nv  consensus  35.0  male   \n",
       "4   1257  HAM_0004720  ISIC_0027277  mel      histo  40.0  male   \n",
       "\n",
       "      localization        dataset  \n",
       "0             back   vidir_modern  \n",
       "1             back  vidir_molemax  \n",
       "2  lower extremity      rosendahl  \n",
       "3  upper extremity   vidir_modern  \n",
       "4  lower extremity   vidir_modern  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c108002e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161</td>\n",
       "      <td>HAM_0005386</td>\n",
       "      <td>ISIC_0033973</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6143</td>\n",
       "      <td>HAM_0005593</td>\n",
       "      <td>ISIC_0029658</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2738</td>\n",
       "      <td>HAM_0005757</td>\n",
       "      <td>ISIC_0026496</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9515</td>\n",
       "      <td>HAM_0005115</td>\n",
       "      <td>ISIC_0033766</td>\n",
       "      <td>nv</td>\n",
       "      <td>consensus</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1257</td>\n",
       "      <td>HAM_0004720</td>\n",
       "      <td>ISIC_0027277</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age   sex  \\\n",
       "0    161  HAM_0005386  ISIC_0033973  bkl      histo  45.0  male   \n",
       "1   6143  HAM_0005593  ISIC_0029658   nv  follow_up  45.0  male   \n",
       "2   2738  HAM_0005757  ISIC_0026496  bcc      histo  70.0  male   \n",
       "3   9515  HAM_0005115  ISIC_0033766   nv  consensus  35.0  male   \n",
       "4   1257  HAM_0004720  ISIC_0027277  mel      histo  40.0  male   \n",
       "\n",
       "      localization        dataset  risk  \n",
       "0             back   vidir_modern   0.0  \n",
       "1             back  vidir_molemax   1.0  \n",
       "2  lower extremity      rosendahl   3.0  \n",
       "3  upper extremity   vidir_modern   1.0  \n",
       "4  lower extremity   vidir_modern   3.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc009eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10015/10015 [00:36<00:00, 274.00it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (150,200))\n",
    "    img = image.img_to_array(img) / 255.0\n",
    "    \n",
    "    \n",
    "    X.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c8ddf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 150, 200, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be148cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "\n",
    "for ele in df['risk']:\n",
    "    risk.append(tf.one_hot(int(ele), 4))\n",
    "    \n",
    "y = np.array(risk)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efe53a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model = models.Sequential()\n",
    "ori_model.add(layers.Conv2D(64, (3, 3), activation='tanh', input_shape=(150,200,3)))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Conv2D(32, (3, 3), activation='tanh'))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Conv2D(16, (3, 3), activation='tanh'))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Flatten(name=\"feature_output\"))\n",
    "\n",
    "ori_model.add(layers.Dense(1024, activation='relu'))\n",
    "ori_model.add(layers.Dense(256, activation='relu'))\n",
    "ori_model.add(layers.Dense(64, activation='relu'))\n",
    "ori_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ebdf19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9013 samples, validate on 1002 samples\n",
      "Epoch 1/25\n",
      "9013/9013 [==============================] - 14s 2ms/sample - loss: 0.9155 - accuracy: 0.6640 - val_loss: 0.8845 - val_accuracy: 0.6796\n",
      "Epoch 2/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.7277 - accuracy: 0.7023 - val_loss: 0.7839 - val_accuracy: 0.6537\n",
      "Epoch 3/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.6931 - accuracy: 0.7132 - val_loss: 0.8402 - val_accuracy: 0.6587\n",
      "Epoch 4/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.6695 - accuracy: 0.7289 - val_loss: 0.7526 - val_accuracy: 0.7006\n",
      "Epoch 5/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.6512 - accuracy: 0.7350 - val_loss: 0.8685 - val_accuracy: 0.6717\n",
      "Epoch 6/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.6212 - accuracy: 0.7469 - val_loss: 0.7939 - val_accuracy: 0.7156\n",
      "Epoch 7/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.5990 - accuracy: 0.7606 - val_loss: 0.6705 - val_accuracy: 0.7385\n",
      "Epoch 8/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.5738 - accuracy: 0.7740 - val_loss: 0.6828 - val_accuracy: 0.7385\n",
      "Epoch 9/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.5343 - accuracy: 0.7887 - val_loss: 1.4175 - val_accuracy: 0.5210\n",
      "Epoch 10/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.4877 - accuracy: 0.8108 - val_loss: 0.8926 - val_accuracy: 0.7335\n",
      "Epoch 11/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.4462 - accuracy: 0.8320 - val_loss: 0.9560 - val_accuracy: 0.7275\n",
      "Epoch 12/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.3981 - accuracy: 0.8483 - val_loss: 1.2743 - val_accuracy: 0.6597\n",
      "Epoch 13/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.3510 - accuracy: 0.8672 - val_loss: 1.3190 - val_accuracy: 0.6747\n",
      "Epoch 14/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.2791 - accuracy: 0.8938 - val_loss: 1.1351 - val_accuracy: 0.7136\n",
      "Epoch 15/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.2353 - accuracy: 0.9161 - val_loss: 1.3085 - val_accuracy: 0.7076\n",
      "Epoch 16/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.1985 - accuracy: 0.9271 - val_loss: 1.2607 - val_accuracy: 0.7186\n",
      "Epoch 17/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.1581 - accuracy: 0.9431 - val_loss: 1.1386 - val_accuracy: 0.7485\n",
      "Epoch 18/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.1413 - accuracy: 0.9497 - val_loss: 1.3111 - val_accuracy: 0.7325\n",
      "Epoch 19/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.1093 - accuracy: 0.9632 - val_loss: 2.9154 - val_accuracy: 0.6976\n",
      "Epoch 20/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.1350 - accuracy: 0.9530 - val_loss: 1.5196 - val_accuracy: 0.7236\n",
      "Epoch 21/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.1026 - accuracy: 0.9645 - val_loss: 1.3489 - val_accuracy: 0.7485\n",
      "Epoch 22/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.0836 - accuracy: 0.9733 - val_loss: 1.7724 - val_accuracy: 0.7036\n",
      "Epoch 23/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.0836 - accuracy: 0.9731 - val_loss: 1.6972 - val_accuracy: 0.7255\n",
      "Epoch 24/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.0489 - accuracy: 0.9839 - val_loss: 1.3931 - val_accuracy: 0.6876\n",
      "Epoch 25/25\n",
      "9013/9013 [==============================] - 13s 1ms/sample - loss: 0.0849 - accuracy: 0.9728 - val_loss: 20.7441 - val_accuracy: 0.5858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1854f2b0e08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "ori_model.fit(X, y, epochs=25, validation_split=0.1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b27ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ori_model.history.history['loss']\n",
    "val_loss = ori_model.history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('Origin_Loss.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02de0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = ori_model.history.history['accuracy']\n",
    "val_acc = ori_model.history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.savefig('Origin_Acc.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "874f4848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10015/10015 [00:05<00:00, 1719.31it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    sex = 0 if df.iloc[i]['sex'] == 'male' else 1\n",
    "    age = df.iloc[i]['age']\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array([sex, age])\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15)))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15)))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15)))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15)))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15)))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15)))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15)))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15)))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15)))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15)))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15)))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15)))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15)))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15)))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15)))\n",
    "\n",
    "    feature_vector.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f2a4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d845da5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa924c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=ori_model.inputs,\n",
    "    outputs=ori_model.get_layer(name=\"feature_output\").output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5601979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10015,148,198,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-504d99f30878>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m   1133\u001b[0m           call_from_convolution=False)\n\u001b[0;32m   1134\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;31m# copybara:strip_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   2009\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m                            name=name)\n\u001b[0m\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m    934\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0;32m   1021\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m-> 1022\u001b[1;33m                              ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m   1023\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m     _execute.record_gradient(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10015,148,198,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "image_features = feature_extractor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for img_feat, feat in zip(image_features, feature_vector):\n",
    "    X.append(np.concatenate((img_feat, feat)))\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a93336",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=25, validation_split=0.1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6463d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
