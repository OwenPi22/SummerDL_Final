{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9c9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import activations\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261c3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddfe42",
   "metadata": {},
   "source": [
    "(Warning for Sunlight, increased risk of cancer) Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "(Skin cancer) basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "(HARMLESS) benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "(HARMLESS) dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "(Not entirely harmless) melanocytic nevi (__nv__)   5\n",
    "\n",
    "(HARMLESS) vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544945c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  \n",
       "0  vidir_modern  \n",
       "1  vidir_modern  \n",
       "2  vidir_modern  \n",
       "3  vidir_modern  \n",
       "4  vidir_modern  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89856d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>HAM_0001473</td>\n",
       "      <td>ISIC_0029022</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5898</td>\n",
       "      <td>HAM_0001225</td>\n",
       "      <td>ISIC_0025977</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2743</td>\n",
       "      <td>HAM_0004880</td>\n",
       "      <td>ISIC_0028583</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>rosendahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4346</td>\n",
       "      <td>HAM_0007554</td>\n",
       "      <td>ISIC_0028193</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1904</td>\n",
       "      <td>HAM_0004844</td>\n",
       "      <td>ISIC_0033394</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age     sex  \\\n",
       "0     96  HAM_0001473  ISIC_0029022  bkl      histo  70.0    male   \n",
       "1   5898  HAM_0001225  ISIC_0025977   nv  follow_up  25.0  female   \n",
       "2   2743  HAM_0004880  ISIC_0028583  bcc      histo  65.0    male   \n",
       "3   4346  HAM_0007554  ISIC_0028193   nv  follow_up  55.0  female   \n",
       "4   1904  HAM_0004844  ISIC_0033394  mel      histo  50.0    male   \n",
       "\n",
       "      localization        dataset  \n",
       "0             face   vidir_modern  \n",
       "1            trunk  vidir_molemax  \n",
       "2             back      rosendahl  \n",
       "3  lower extremity  vidir_molemax  \n",
       "4            trunk   vidir_modern  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3064aeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['face', 'trunk', 'back', 'lower extremity', 'foot',\n",
       "       'upper extremity', 'abdomen', 'unknown', 'scalp', 'hand', 'chest',\n",
       "       'neck', 'ear', 'genital', 'acral'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['localization'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a12ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10015/10015 [00:08<00:00, 1228.78it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    sex = 0.5 if df.iloc[i]['sex'] == 'male' else -0.5\n",
    "    age = df.iloc[i]['age'] / 80\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array([age, sex])\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15) - 0.5))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15) - 0.5))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15) - 0.5))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15) - 0.5))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15) - 0.5))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15) - 0.5))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15) - 0.5))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15) - 0.5))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15) - 0.5))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15) - 0.5))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15) - 0.5))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15) - 0.5))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15) - 0.5))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15) - 0.5))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15) - 0.5))\n",
    "\n",
    "    feature_vector.append(feat)\n",
    "    \n",
    "feat_X = np.array(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a5e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10015/10015 [05:25<00:00, 30.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "VGG_load = VGG16(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat = feat_X[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(25088)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, feat)))\n",
    "    \n",
    "df['VGG16'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88325339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception\n",
    "preprocessed = []\n",
    "\n",
    "IV3_load = InceptionV3(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(IV3_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat = feat_X[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(131072)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, feat)))\n",
    "    \n",
    "df['IV3'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0493b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet152V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat = feat_X[i]    \n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, feat)))\n",
    "    \n",
    "df['resnet'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d4b2329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>VGG16</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>HAM_0001473</td>\n",
       "      <td>ISIC_0029022</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5898</td>\n",
       "      <td>HAM_0001225</td>\n",
       "      <td>ISIC_0025977</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>[1.7461514472961426, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2743</td>\n",
       "      <td>HAM_0004880</td>\n",
       "      <td>ISIC_0028583</td>\n",
       "      <td>bcc</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>rosendahl</td>\n",
       "      <td>[0.0, 0.0, 6.205324649810791, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4346</td>\n",
       "      <td>HAM_0007554</td>\n",
       "      <td>ISIC_0028193</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>vidir_molemax</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.96051025390625, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1904</td>\n",
       "      <td>HAM_0004844</td>\n",
       "      <td>ISIC_0033394</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    lesion_id      image_id   dx    dx_type   age     sex  \\\n",
       "0     96  HAM_0001473  ISIC_0029022  bkl      histo  70.0    male   \n",
       "1   5898  HAM_0001225  ISIC_0025977   nv  follow_up  25.0  female   \n",
       "2   2743  HAM_0004880  ISIC_0028583  bcc      histo  65.0    male   \n",
       "3   4346  HAM_0007554  ISIC_0028193   nv  follow_up  55.0  female   \n",
       "4   1904  HAM_0004844  ISIC_0033394  mel      histo  50.0    male   \n",
       "\n",
       "      localization        dataset  \\\n",
       "0             face   vidir_modern   \n",
       "1            trunk  vidir_molemax   \n",
       "2             back      rosendahl   \n",
       "3  lower extremity  vidir_molemax   \n",
       "4            trunk   vidir_modern   \n",
       "\n",
       "                                               VGG16  risk  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   0.0  \n",
       "1  [1.7461514472961426, 0.0, 0.0, 0.0, 0.0, 0.0, ...   1.0  \n",
       "2  [0.0, 0.0, 6.205324649810791, 0.0, 0.0, 0.0, 0...   3.0  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.96051025390625, 0....   1.0  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   3.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc3f96",
   "metadata": {},
   "source": [
    "# 1000 Images for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba749bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.001,\n",
    "  patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b7bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_X_trn = np.array(df['VGG16'])[:-1000]\n",
    "#IV3_X_trn = np.array(df['IV3'])[:-1000]\n",
    "#RES_X_trn = np.array(df['resnet'])[:-1000]\n",
    "\n",
    "VGG_X_val = np.array(df['VGG16'])[-1000:]\n",
    "#IV3_X_val = np.array(df['IV3'])[-1000:]\n",
    "#RES_X_val = np.array(df['resnet'])[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a30f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn = np.array(df['risk'])[:-1000]\n",
    "y_val = np.array(df['risk'])[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3df598",
   "metadata": {},
   "source": [
    "# VGG model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c802b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9015, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_trn = []\n",
    "for ele in y_trn:\n",
    "    new_y_trn.append(tf.one_hot(int(ele), 4))\n",
    "    \n",
    "new_y_trn = np.array(new_y_trn)\n",
    "\n",
    "new_y_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11e5a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_val = []\n",
    "for ele in y_val:\n",
    "    new_y_val.append(tf.one_hot(int(ele), 4))\n",
    "    \n",
    "new_y_val = np.array(new_y_val)\n",
    "\n",
    "new_y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af949771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9015/9015 [00:00<00:00, 13470.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9015, 25105)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_VGG_trn = []\n",
    "\n",
    "for i in tqdm(range(0, 9015)):\n",
    "    new_VGG_trn.append(np.array(VGG_X_trn[i]))\n",
    "\n",
    "new_VGG_trn = np.array(new_VGG_trn)\n",
    "\n",
    "new_VGG_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "961e515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 11018.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 25105)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_VGG_val = []\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    new_VGG_val.append(np.array(VGG_X_val[i]))\n",
    "\n",
    "new_VGG_val = np.array(new_VGG_val)\n",
    "\n",
    "new_VGG_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2a96b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = models.Sequential()\n",
    "vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "vgg_model.add(layers.Dense(2048, activation='relu'))\n",
    "vgg_model.add(layers.Dense(1024, activation='relu'))\n",
    "vgg_model.add(layers.Dense(512, activation='relu'))\n",
    "vgg_model.add(layers.Dense(128, activation='relu'))\n",
    "vgg_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5801ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9015 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "9015/9015 [==============================] - 13s 1ms/sample - loss: 2.5586 - accuracy: 0.6647 - val_loss: 0.9268 - val_accuracy: 0.6730\n",
      "Epoch 2/20\n",
      "9015/9015 [==============================] - 12s 1ms/sample - loss: 0.9525 - accuracy: 0.6691 - val_loss: 0.9288 - val_accuracy: 0.6730\n",
      "Epoch 3/20\n",
      "9015/9015 [==============================] - 12s 1ms/sample - loss: 0.9519 - accuracy: 0.6691 - val_loss: 0.9294 - val_accuracy: 0.6730\n",
      "Epoch 4/20\n",
      "9015/9015 [==============================] - 12s 1ms/sample - loss: 0.9533 - accuracy: 0.6691 - val_loss: 0.9271 - val_accuracy: 0.6730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x198b1b7edc8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "vgg_model.fit(new_VGG_trn, new_y_trn, \n",
    "              epochs=20, \n",
    "              validation_data=(new_VGG_val, new_y_val), \n",
    "              callbacks=[earlystop_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f74b4",
   "metadata": {},
   "source": [
    "# ResNet setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_RES_trn = []\n",
    "\n",
    "for i in tqdm(range(0, 9015)):\n",
    "    new_RES_trn.append(np.array(RES_X_trn[i]))\n",
    "\n",
    "new_RES_trn = np.array(new_RES_trn)\n",
    "\n",
    "new_RES_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a766ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_RES_val = []\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    new_RES_val.append(np.array(RES_X_val[i]))\n",
    "\n",
    "new_RES_val = np.array(new_RES_val)\n",
    "\n",
    "new_RES_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = models.Sequential()\n",
    "#res_model.add(layers.Dense(8192, activation='relu'))\n",
    "res_model.add(layers.Dense(4096, activation='relu'))\n",
    "#res_model.add(layers.Dense(2048, activation='relu'))\n",
    "res_model.add(layers.Dense(1024, activation='relu'))\n",
    "#res_model.add(layers.Dense(512, activation='relu'))\n",
    "res_model.add(layers.Dense(128, activation='relu'))\n",
    "res_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "res_model.fit(new_RES_trn, new_y_trn, \n",
    "              epochs=10, callbacks=[earlystop_callback],\n",
    "              validation_data=(new_RES_val, new_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496aae8",
   "metadata": {},
   "source": [
    "# Inception V3 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a49d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_IV3_trn = []\n",
    "\n",
    "for i in tqdm(range(0, 9015)):\n",
    "    new_IV3_trn.append(np.array(IV3_X_trn[i]))\n",
    "\n",
    "new_IV3_trn = np.array(new_IV3_trn)\n",
    "\n",
    "new_IV3_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_IV3_val = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    new_IV3_val.append(np.array(IV3_X_val[i]))\n",
    "\n",
    "new_IV3_val = np.array(new_IV3_val)\n",
    "\n",
    "new_IV3_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model = models.Sequential()\n",
    "#iv3_model.add(layers.Dense(8192, activation='relu'))\n",
    "iv3_model.add(layers.Dense(1024, activation='relu'))\n",
    "#iv3_model.add(layers.Dense(2048, activation='relu'))\n",
    "iv3_model.add(layers.Dense(256, activation='relu'))\n",
    "#iv3_model.add(layers.Dense(512, activation='relu'))\n",
    "#iv3_model.add(layers.Dense(128, activation='relu'))\n",
    "iv3_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "iv3_model.fit(new_IV3_trn, new_y_trn, \n",
    "              epochs=10, callbacks=[earlystop_callback]\n",
    "              validation_data=(new_IV3_val, new_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe5ab4",
   "metadata": {},
   "source": [
    "# Making the confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_iv3_val = []\n",
    "temp_iv3_trn = iv3_model.predict(new_IV3_trn)\n",
    "temp_iv3_val = iv3_model.predict(new_IV3_val)\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    pred = np.argmax(temp_iv3_val[i])\n",
    "    predict_y_iv3_val.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69b505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 334154.24it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_y_vgg_val = []\n",
    "temp_vgg_trn = vgg_model.predict(new_VGG_trn)\n",
    "temp_vgg_val = vgg_model.predict(new_VGG_val)\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    pred = np.argmax(temp_vgg_val[i])\n",
    "    predict_y_vgg_val.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_res_val = []\n",
    "temp_res_val = res_model.predict(new_RES_val)\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    pred = np.argmax(temp_res_val[i])\n",
    "    predict_y_res_val.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d311ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_iv3 = tf.math.confusion_matrix(np.array(df['risk'])[:-1000], np.array(predict_y_iv3_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(predict_y_vgg_val).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d41b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_vgg = tf.math.confusion_matrix(np.array(df['risk'])[-1000:], np.array(predict_y_vgg_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_res = tf.math.confusion_matrix(np.array(df['risk'])[:-1000], np.array(predict_y_res_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37fb9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cm_iv3 = np.array(cm_iv3).astype('float32')\n",
    "cm_vgg = np.array(cm_vgg).astype('float32')\n",
    "#cm_res = np.array(cm_res).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d6d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cm_iv3[0] = cm_iv3[0] / (1.0 * cm_iv3[0].sum())\n",
    "#cm_iv3[1] = cm_iv3[1] / (1.0 * cm_iv3[1].sum())\n",
    "#cm_iv3[2] = cm_iv3[2] / (1.0 * cm_iv3[2].sum())\n",
    "#cm_iv3[3] = cm_iv3[3] / (1.0 * cm_iv3[3].sum())\n",
    "\n",
    "cm_vgg[0] = cm_vgg[0] / (1.0 * cm_vgg[0].sum())\n",
    "cm_vgg[1] = cm_vgg[1] / (1.0 * cm_vgg[1].sum())\n",
    "cm_vgg[2] = cm_vgg[2] / (1.0 * cm_vgg[2].sum())\n",
    "cm_vgg[3] = cm_vgg[3] / (1.0 * cm_vgg[3].sum())\n",
    "\n",
    "#cm_res[0] = cm_res[0] / (1.0 * cm_res[0].sum())\n",
    "#cm_res[1] = cm_res[1] / (1.0 * cm_res[1].sum())\n",
    "#cm_res[2] = cm_res[2] / (1.0 * cm_res[2].sum())\n",
    "#cm_res[3] = cm_res[3] / (1.0 * cm_res[3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a220d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#sns.heatmap(cm_iv3, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e3c9334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUqklEQVR4nO3df2yd1X3H8c/HTtIyfqTSaEtsp020pGtYM0gb0lYVFEYh4UeIJaokSIGtipYhoIO2CqNaBC0DRvcjHUhs1FsRtBuFrJ1GgExQdXTAVKizwjJifiwhiNgmZbRNGStbYvu7P3zJvY1s33vx9XOeHL9f6Ej3ee7jc786evjm6JzznMcRIQBAMdpSBwAA0wlJFwAKRNIFgAKRdAGgQCRdACgQSRcACkTSBYBx2L7D9qu2nxnne9u+1fYu2ztsf7henSRdABjfnZJWTPD9OZIWVsoGSX9Vr0KSLgCMIyIelfTTCS5ZJekbMeoJSe+yPWeiOme0MsAxf2BWJ4+8Vbw5+FjqEErjqI5TU4eAEho6MODJ1nHwtRcbzjmz3v1rv6fRHupbeiKip4mf65S0t+a4v3LulfH+YMqTLgAUamS44UsrCbaZJDtpJF0AeYmRIn9tQNLcmuOuyrlxMaYLIC8jI42Xydsq6ZLKKoaPSfp5RIw7tCDR0wWQmWhhT9f2tySdLul42/2SrpM0c/R34nZJ2ySdK2mXpF9I+ky9Okm6APIyPNSyqiLiojrfh6TLm6mTpAsgL01MpKVA0gWQl2In0ppG0gWQl9ZMkE0Zki6ArLRyIm0qkHQB5IWeLgAUaPhg6ggmRNIFkBeGFwCgQAwvAECB6OkCQIHo6QJAcWKEiTQAKA49XQAoEGO6AFAgNrwBgALR0wWAAjGmCwAFauEm5lMh+3ekLT/7dO185lE91/e4rt7Y1Abv2dl002addt5ada+7NHUoyXFfVGXXFsW+I61pWSfdtrY23XrLjTp/5TotPukMrVnTrUWLFqYOK5nuc8/S7ZtvSB1GctwXVTm2RcRwwyWFrJPuslOWaPful7Rnz8s6ePCgtmy5TxesXJ46rGSWnrxYs487NnUYyXFfVGXZFiXv6dYd07X9QUmrJHVWTg1I2hoRz05lYK3Q0XmC9vYPHjruH3hFy05ZkjAilAH3RVWWbVHy1QsT9nRt/4GkeyRZ0g8rxZK+ZfuaqQ8PAJp0hPd010v6jYj4pYeZbW+WtFPSzWP9ke0NkjZIkttnq63t6BaE2rzBgX2a29Vx6Lirc44GB/cliQXlwX1RlWVbHOGrF0YkdYxxfk7luzFFRE9ELI2IpakSriT1bn9aCxbM17x5czVz5kytXr1K9z/wcLJ4UA7cF1VZtkWMNF4SqNfTvUrS92z/p6S9lXPvk7RA0hVTGFdLDA8P68qrNmnbg3erva1Nd951r/r6XkgdVjIbr7tZvU/t0P79r+vM7nW6bP3FuvBInzR5G7gvqrJsi5I/HOGImPgCu03SMv3yRFpvNLjeYsaszol/YBp5c/Cx1CGUxlEdp6YOASU0dGDAk63jzQf/ouGcc9R5V03695pVd/VCjL7P+IkCYgGAySv56gUeAwaQl5JPpJF0AeSl5GO6JF0AeWF4AQAKRE8XAApE0gWAAtVZBpsaSRdAXoZYvQAAxSn5RFrW++kCmIZauMuY7RW2n7e9a6ydFW2/z/Yjtp+yvcP2ufXqJOkCyEtE42UCttsl3SbpHEknSrrI9omHXbZJ0paIWCJpraS/rBcewwsA8tK61QvLJO2KiBclyfY9Gn2hQ1/NNSHpuMrn2ZIGVQdJF0Bemki6tXt/V/RERE/lc6equytKUr+kjx5WxZckPWz7s5KOlvSper9J0gWQlRhu/IWTlQTbU/fC8V0k6c6I+HPbH5f0TdsfqmwUNiaSLoC8tG54YUDS3Jrjrsq5WuslrZCkiPiB7XdKOl7Sq+NVykQagLy07s0RvZIW2p5ve5ZGJ8q2HnbNy5LOlCTbiyS9U9J/TVQpPV0AeRlpzRNpETFk+wpJD0lql3RHROy0fb2k7RGxVdIXJP217c9pdFLtd6LOmyFIugDy0sK9FyJim6Rth527tuZzn6RPNFMnSRdAXpqYSEuBpAsgL+wyBgAFatGY7lQh6QLIS8k3vCHpAsgLPV0AKE4wpgsABWL1AgAUiOEFACgQwwsAUCB6ugBQIJaMAUCB6OkCQHFiiNULAFAceroAUCDGdAGgQPR0AaA4QdIFgAIxkQYABaKnCwAFIukCQHHqvIw3OZIugLzQ0wWAApF0AaA4McTDEQBQnHLnXJIugLzwcAQAFImkCwAFKvnwQlvqAKba8rNP185nHtVzfY/r6o2Xpw4nqU03bdZp561V97pLU4eSHPdFVW5tESPRcEkh66Tb1tamW2+5UeevXKfFJ52hNWu6tWjRwtRhJdN97lm6ffMNqcNIjvuiKse2iKFouKSQddJddsoS7d79kvbseVkHDx7Uli336YKVy1OHlczSkxdr9nHHpg4jOe6LqizbYqSJksDbTrq2P9PKQKZCR+cJ2ts/eOi4f+AVdXSckDAilAH3RVWObREjjZcUJtPT/fJ4X9jeYHu77e0jI/8ziZ8AgCaVvKc74eoF2zvG+0rSe8f7u4jokdQjSTNmdSZbvzE4sE9zuzoOHXd1ztHg4L5U4aAkuC+qcmyLkr+tp25P972SLpG0cozyk6kNbfJ6tz+tBQvma968uZo5c6ZWr16l+x94OHVYSIz7oirHtoihxks9tlfYft72LtvXjHPNatt9tnfavrtenfXW6T4g6ZiIeHqMH/p+/ZDTGh4e1pVXbdK2B+9We1ub7rzrXvX1vZA6rGQ2Xnezep/aof37X9eZ3et02fqLdeGRPmnyNnBfVOXYFq3q6dpul3SbpLMk9Uvqtb01Ivpqrlko6YuSPhERP7P9nrr1TvXekymHF8rmzcHHUodQGkd1nJo6BJTQ0IEBT7aOH5/xyYZzznsf+Zdxf8/2xyV9KSKWV46/KEkR8cc11/yJpBci4m8a/c2sl4wBmIbCDZfaSf9K2VBTU6ekvTXH/ZVztT4g6QO2/9X2E7ZX1AuPx4ABZKWZ4YXaSf+3aYakhZJOl9Ql6VHbiyNi/0R/AADZiJFJj1C8ZUDS3Jrjrsq5Wv2SnoyIg5L22H5Bo0m4d7xKGV4AkJWRYTdc6uiVtND2fNuzJK2VtPWwa/5Ro71c2T5eo8MNL05UKT1dAFlp1eqFiBiyfYWkhyS1S7ojInbavl7S9ojYWvnubNt9koYlbYyICZfTknQBZKWFwwuKiG2Sth127tqazyHp85XSEJIugKyU/A3sJF0AeWllT3cqkHQBZKWBCbKkSLoAskJPFwAKFEHSBYDClH1rR5IugKyM0NMFgOIwvAAABWL1AgAUiNULAFAgxnQBoECM6QJAgdh7AQAKxPACABRohIk0ACgOPV0AKBATaQBQIHq6AFCgki9eIOkCyMvwSLlfck7SBZCVku/sSNIFkJcQY7oAUJiRkg/qknQBZGWEni4AFIfhBQAo0DBJFwCKw+oFACgQSRcACsSYLgAUqOQ7O5J0AeSFJWMAUKDh1AHUQdIFkJUR09MFgMKU/Clgki6AvJR9yVi5N54EgCaNuPFSj+0Vtp+3vcv2NRNcd6HtsL20Xp30dAFkpVWPAdtul3SbpLMk9Uvqtb01IvoOu+5YSVdKerKReunpAshKC3u6yyTtiogXI+KApHskrRrjuj+S9BVJ/9tIfCRdAFkZaaLY3mB7e03ZUFNVp6S9Ncf9lXOH2P6wpLkR8WCj8WWfdJeffbp2PvOonut7XFdvvDx1OEltummzTjtvrbrXXZo6lOS4L6pya4topkT0RMTSmtLT6O/YbpO0WdIXmokv66Tb1tamW2+5UeevXKfFJ52hNWu6tWjRwtRhJdN97lm6ffMNqcNIjvuiKse2aOHwwoCkuTXHXZVzbzlW0ockfd/2S5I+Jmlrvcm0uknX9gdtn2n7mMPOr6gbcmLLTlmi3btf0p49L+vgwYPasuU+XbByeeqwkll68mLNPu7Y1GEkx31RlWNbNDO8UEevpIW259ueJWmtpK1vfRkRP4+I4yNiXkTMk/SEpAsiYvtElU6YdG3/vqT7JH1W0jO2aweRb6ofc1odnSdob//goeP+gVfU0XFCwohQBtwXVTm2xbAbLxOJiCFJV0h6SNKzkrZExE7b19u+4O3GV2/J2O9K+khEvGF7nqRv254XEbdI46/LqAxGb5Akt89WW9vRbzc+AGhKKx+OiIhtkrYddu7aca49vZE66yXdtoh4o1LhS7ZP12jifb8mSLqVwegeSZoxqzPZU3mDA/s0t6vj0HFX5xwNDu5LFQ5KgvuiKse2ONKfSPux7ZPfOqgk4PMlHS9p8RTG1RK925/WggXzNW/eXM2cOVOrV6/S/Q88nDosJMZ9UZVjWzSzeiGFej3dSyQN1Z6ojHNcYvtrUxZViwwPD+vKqzZp24N3q72tTXfeda/6+l5IHVYyG6+7Wb1P7dD+/a/rzO51umz9xbrwCJ80eTu4L6pybIuyb2LuiKnN9ymHF8rmzcHHUodQGkd1nJo6BJTQ0IGBSafMr75vXcM553Mv/23hKZq9FwBkhU3MAaBAZR9eIOkCyErZVy+QdAFkpeyTSCRdAFkZKXnaJekCyAoTaQBQIMZ0AaBArF4AgAIxpgsABSp3yiXpAsgMY7oAUKDhkvd1SboAskJPFwAKxEQaABSo3CmXpAsgMwwvAECBmEgDgAIxpgsABSp3yiXpAsgMPV0AKBATaQBQoKCnCwDFYfUCABSI4QUAKNBI0NMFgMKUO+WSdAFkhiVjAFAgVi8AQIGGSLoAUJyy93TbUgcAAK000kSpx/YK28/b3mX7mjG+/7ztPts7bH/P9vvr1UnSBZCViGi4TMR2u6TbJJ0j6URJF9k+8bDLnpK0NCJ+U9K3Jf1JvfhIugCyMqJouNSxTNKuiHgxIg5IukfSqtoLIuKRiPhF5fAJSV31KiXpAsjKsKLhYnuD7e01ZUNNVZ2S9tYc91fOjWe9pH+qFx8TaQCy0sw63YjokdQz2d+0vU7SUkmfrHctSRdAVuqN1TZhQNLcmuOuyrlfYvtTkv5Q0icj4v/qVcrwAoCstHD1Qq+khbbn254laa2krbUX2F4i6WuSLoiIVxuJj54ugKy0ap1uRAzZvkLSQ5LaJd0RETttXy9pe0RslfSnko6R9Pe2JenliLhgonpJugCy0sq9FyJim6Rth527tubzp5qtk6QLICvDUe4ddUm6ALJS9seASboAssIm5gBQoHKnXJIugMywiTkAFKjsSTf7hyOWn326dj7zqJ7re1xXb7w8dThJbbpps047b626112aOpTkuC+qcmuL4RhpuKSQddJta2vTrbfcqPNXrtPik87QmjXdWrRoYeqwkuk+9yzdvvmG1GEkx31RlWNbRBP/pZB10l12yhLt3v2S9ux5WQcPHtSWLffpgpXLU4eVzNKTF2v2ccemDiM57ouqHNuiVfvpTpW6Sdf2MtunVD6fWNkp/dypD23yOjpP0N7+wUPH/QOvqKPjhIQRoQy4L6pybIsW7qc7JSacSLN9nUZ3TZ9h+7uSPirpEUnX2F4SETcWECMANCxVD7ZR9VYvfFrSyZLeIWmfpK6IeN32n0l6UtKYSbeyEfAGSXL7bLW1Hd2ygJsxOLBPc7s6Dh13dc7R4OC+JLGgPLgvqnJsi+GG3n6WTr3hhaGIGK68jmJ3RLwuSRHxpibYGS0ieiJiaUQsTZVwJal3+9NasGC+5s2bq5kzZ2r16lW6/4GHk8WDcuC+qMqxLUYiGi4p1OvpHrD9K5Wk+5G3TtqercZeppnU8PCwrrxqk7Y9eLfa29p05133qq/vhdRhJbPxupvV+9QO7d//us7sXqfL1l+sC4/wSZO3g/uiKse2KPveC55o/MP2O8baCd328ZLmRMR/1PuBGbM6y90CBXpz8LHUIZTGUR2npg4BJTR0YMCTrWPRe5Y1nHOeffWHk/69Zk3Y0x3v1RMR8Zqk16YkIgCYhLL3dHkMGEBW2GUMAArEJuYAUCCGFwCgQEFPFwCKU/atHUm6ALJypD8GDABHFHq6AFCg4RHGdAGgMKxeAIACMaYLAAViTBcACkRPFwAKxEQaABSI4QUAKBDDCwBQILZ2BIACsU4XAApETxcACjRS8q0d672CHQCOKBHRcKnH9grbz9veZfuaMb5/h+17K98/aXtevTpJugCy0qqka7td0m2SzpF0oqSLbJ942GXrJf0sIhZI+qqkr9SLj6QLICvRRKljmaRdEfFiRByQdI+kVYdds0rSXZXP35Z0pu0JX+s+5WO6rXiPfSvY3hARPanjKIMytMXQgYGUP39IGdqiLHJpi2Zyju0NkjbUnOqpaYNOSXtrvuuX9NHDqjh0TUQM2f65pF+V9Np4vzmderob6l8ybdAWVbRF1bRri4joiYilNWXK/9GZTkkXAJoxIGluzXFX5dyY19ieIWm2pJ9MVClJFwDG1itpoe35tmdJWitp62HXbJX025XPn5b0z1Fnhm46rdM94seqWoi2qKItqmiLGpUx2iskPSSpXdIdEbHT9vWStkfEVklfl/RN27sk/VSjiXlCLvvmEACQE4YXAKBAJF0AKFD2SbfeY3zTie07bL9q+5nUsaRke67tR2z32d5p+8rUMaVi+522f2j73ytt8eXUMeUu6zHdymN8L0g6S6MLm3slXRQRfUkDS8T2aZLekPSNiPhQ6nhSsT1H0pyI+JHtYyX9m6Tu6XhfVJ6eOjoi3rA9U9Ljkq6MiCcSh5at3Hu6jTzGN21ExKManWGd1iLilYj4UeXzf0t6VqNPFk07MeqNyuHMSsm3J1YCuSfdsR7jm5b/c2FslV2hlkh6MnEoydhut/20pFclfTcipm1bFCH3pAuMy/Yxkr4j6aqIeD11PKlExHBEnKzRJ66W2Z62Q09FyD3pNvIYH6ahyvjldyT9XUT8Q+p4yiAi9kt6RNKKxKFkLfek28hjfJhmKpNHX5f0bERsTh1PSrbfbftdlc9HaXTS+bmkQWUu66QbEUOS3nqM71lJWyJiZ9qo0rH9LUk/kPTrtvttr08dUyKfkHSxpN+y/XSlnJs6qETmSHrE9g6NdlK+GxEPJI4pa1kvGQOAssm6pwsAZUPSBYACkXQBoEAkXQAoEEkXAApE0gWAApF0AaBA/w/+3cBV2AhwvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_vgg, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f250af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_res, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9ca5d",
   "metadata": {},
   "source": [
    "# Stacking the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_trn = []\n",
    "\n",
    "for i in tqdm(range(0, 9015)):\n",
    "    feat = np.concatenate(( (temp_iv3_trn[i] - 9) / 10.0, \n",
    "                            (temp_vgg_trn[i] + 1) / 10.0, \n",
    "                            (temp_res_trn[i] + 6) / 10.0 ))\n",
    "    new_X_trn.append(feat)\n",
    "    \n",
    "new_X_trn = np.array(new_X_trn)\n",
    "new_X_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_val = []\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    feat = np.concatenate(( (temp_iv3_val[i] - 9) / 10.0, \n",
    "                            (temp_vgg_val[i] + 1) / 10.0, \n",
    "                            (temp_res_val[i] + 6) / 10.0 ))\n",
    "    new_X_val.append(feat)\n",
    "    \n",
    "new_X_va; = np.array(new_X_val)\n",
    "new_X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda47b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = models.Sequential()\n",
    "\n",
    "final_model.add(layers.Dense(64, activation='relu'))\n",
    "final_model.add(layers.Dense(32, activation='relu'))\n",
    "final_model.add(layers.Dense(16, activation='relu'))\n",
    "final_model.add(layers.Dense(8, activation='relu'))\n",
    "final_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24692f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "final_model.fit(new_X_trn, new_y_trn, \n",
    "                epochs=10, callbacks=[earlystop_callback]\n",
    "                validation_data=(new_X_val, new_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35271d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_final_val = []\n",
    "temp_final_val = final_model.predict(new_X_val)\n",
    "\n",
    "for i in tqdm(range(0, 1000)):\n",
    "    pred = np.argmax(temp_final_val[i])\n",
    "    predict_y_final_val.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea11ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_final = tf.math.confusion_matrix(np.array(df['risk'])[:-1000], np.array(predict_y_final_val))\n",
    "\n",
    "cm_final = np.array(cm_final).astype('float32')\n",
    "\n",
    "cm_final[0] = cm_final[0] / (1.0 * cm_final[0].sum())\n",
    "cm_final[1] = cm_final[1] / (1.0 * cm_final[1].sum())\n",
    "cm_final[2] = cm_final[2] / (1.0 * cm_final[2].sum())\n",
    "cm_final[3] = cm_final[3] / (1.0 * cm_final[3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ec177",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_final, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f402f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e625fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a67d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf1959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68924655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995f13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0193ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a712ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7bfae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff753dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf080d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda7ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd58273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6bf90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247e136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fde22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd95d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca237e14",
   "metadata": {},
   "source": [
    "# New Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effce3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61549d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,1, figsize=(15,30), sharex=True)\n",
    "\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 0.0], color='green', stat='probability', ax=axs[0]).set_title('risk 0')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 1.0], color='yellow', stat='probability', ax=axs[1]).set_title('risk 1')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 2.0], color='orange', stat='probability', ax=axs[2]).set_title('risk 2')\n",
    "sns.histplot(x='localization', data=df[df['risk'] == 3.0], color='red', stat='probability', ax=axs[3]).set_title('risk 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8907408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (150,200))\n",
    "    img = image.img_to_array(img) / 255.0\n",
    "    \n",
    "    \n",
    "    X.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = []\n",
    "\n",
    "for ele in df['risk']:\n",
    "    risk.append(tf.one_hot(int(ele), 4))\n",
    "    \n",
    "y = np.array(risk)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fee77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model = models.Sequential()\n",
    "ori_model.add(layers.Conv2D(64, (3, 3), activation='tanh', input_shape=(150,200,3)))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Conv2D(32, (3, 3), activation='tanh'))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Conv2D(16, (3, 3), activation='tanh'))\n",
    "ori_model.add(layers.BatchNormalization())\n",
    "ori_model.add(layers.Activation(activations.elu))\n",
    "ori_model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "ori_model.add(layers.Flatten(name=\"feature_output\"))\n",
    "\n",
    "ori_model.add(layers.Dense(1024, activation='relu'))\n",
    "ori_model.add(layers.Dense(256, activation='relu'))\n",
    "ori_model.add(layers.Dense(64, activation='relu'))\n",
    "ori_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "ori_model.fit(X, y, epochs=25, validation_split=0.1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5119ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model.save('./models/feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"./models/feature\")\n",
    "\n",
    "\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=loaded_model.inputs,\n",
    "    outputs=loaded_model.get_layer(name=\"feature_output\").output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f93869",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    sex = 0 if df.iloc[i]['sex'] == 'male' else 1\n",
    "    age = df.iloc[i]['age']\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array([sex, age])\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15)))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15)))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15)))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15)))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15)))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15)))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15)))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15)))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15)))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15)))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15)))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15)))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15)))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15)))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15)))\n",
    "\n",
    "    feature_vector.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3013ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = feature_extractor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd43b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for img_feat, feat in zip(image_features, feature_vector):\n",
    "    X.append(np.concatenate((img_feat, feat)))\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94dcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=25, validation_split=0.1, batch_size=16, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd7666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675306d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c933e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186014f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef2a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ddfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2d761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ab873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8b6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f79c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6a057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd864c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ce2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append('no')\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append('lo')\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append('md')\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append('hi')\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d46b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_id'] = df['image_id'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16\n",
    "VGG_load = VGG16(weights='imagenet')\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f10b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=90, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True, preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
    "    vertical_flip=True, validation_split=0.1, zoom_range=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29185a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ead26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='training').class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='validation').class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {'hi':1, 'lo':0.25, 'md':5, 'no':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db25929",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    sample_weights.append(class_weights[df.iloc[i]['risk']])\n",
    "    \n",
    "df['weight'] = sample_weights\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x=data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images', weight_col='weight',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='training'),\n",
    "    validation_data=data_gen.flow_from_dataframe(df, directory='./data/HAM10000_images', weight_col='weight',\n",
    "                                          x_col='image_id', y_col='risk', target_size=(224,224),\n",
    "                                          subset='validation'),\n",
    "    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38117486",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    sex = 0 if df.iloc[i]['sex'] == 'male' else 1\n",
    "    age = df.iloc[i]['age']\n",
    "    loc = df.iloc[i]['localization']\n",
    "    \n",
    "    feat = np.array([sex, age])\n",
    "    \n",
    "    if loc == 'abdomen':\n",
    "        feat = np.concatenate((feat, tf.one_hot(0, 15)))\n",
    "    elif loc == 'scalp':\n",
    "        feat = np.concatenate((feat, tf.one_hot(1, 15)))\n",
    "    elif loc == 'lower extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(2, 15)))\n",
    "    elif loc == 'trunk':\n",
    "        feat = np.concatenate((feat, tf.one_hot(3, 15)))\n",
    "    elif loc == 'upper extremity':\n",
    "        feat = np.concatenate((feat, tf.one_hot(4, 15)))\n",
    "    elif loc == 'back':\n",
    "        feat = np.concatenate((feat,tf.one_hot(5, 15)))\n",
    "    elif loc == 'neck':\n",
    "        feat = np.concatenate((feat,tf.one_hot(6, 15)))\n",
    "    elif loc == 'face':\n",
    "        feat = np.concatenate((feat,tf.one_hot(7, 15)))\n",
    "    elif loc == 'chest':\n",
    "        feat = np.concatenate((feat,tf.one_hot(8, 15)))\n",
    "    elif loc == 'foot':\n",
    "        feat = np.concatenate((feat,tf.one_hot(9, 15)))\n",
    "    elif loc == 'ear':\n",
    "        feat = np.concatenate((feat,tf.one_hot(10, 15)))\n",
    "    elif loc == 'unknown':\n",
    "        feat = np.concatenate((feat,tf.one_hot(11, 15)))\n",
    "    elif loc == 'hand':\n",
    "        feat = np.concatenate((feat,tf.one_hot(12, 15)))\n",
    "    elif loc == 'acral':\n",
    "        feat = np.concatenate((feat,tf.one_hot(13, 15)))\n",
    "    elif loc == 'genital':\n",
    "        feat = np.concatenate((feat,tf.one_hot(14, 15)))\n",
    "\n",
    "    feature_vector.append(feat)\n",
    "feature_vector = np.array(feature_vector)\n",
    "\n",
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(feature_vector, return_counts=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=VGG_load.inputs,\n",
    "    outputs=VGG_load.layers[-4].output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = []\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    feat_vec = feature_vector[i]    \n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file, target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    # img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    img_feat = feature_extractor(img)\n",
    "\n",
    "    preprocessed.append(np.concatenate((img_feat, feat_vec)))\n",
    "    \n",
    "preprocessed = np.array(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78572b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohr = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    risk = df.iloc[i]['risk']\n",
    "    \n",
    "    if risk == 'no':\n",
    "        ohr.append(tf.one_hot(0, 4))\n",
    "    elif risk == 'lo':\n",
    "        ohr.append(tf.one_hot(1, 4))\n",
    "    elif risk == 'md':\n",
    "        ohr.append(tf.one_hot(2, 4))\n",
    "    elif risk == 'hi':\n",
    "        ohr.append(tf.one_hot(3, 4))\n",
    "        \n",
    "ohr = np.array(ohr)\n",
    "\n",
    "ohr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ce71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = models.Sequential()\n",
    "new_model.add(layers.Dense(4096, activation='relu'))\n",
    "new_model.add(layers.Dense(2048, activation='relu'))\n",
    "new_model.add(layers.Dense(512, activation='relu'))\n",
    "new_model.add(layers.Dense(128, activation='relu'))\n",
    "new_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec650b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "new_model.fit(preprocessed, ohr, sample_weight=np.array(df['weight']), epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9aaa19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
