{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9c9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import os \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261c3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/HAM10000_Metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02707059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f44649",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddfe42",
   "metadata": {},
   "source": [
    "(Warning for Sunlight, increased risk of cancer) Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "(Skin cancer) basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "(HARMLESS) benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "(HARMLESS) dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "(Not entirely harmless) melanocytic nevi (__nv__)   5\n",
    "\n",
    "(HARMLESS) vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083194f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cases where we can use LSTM\n",
    "\n",
    "(df['lesion_id'].value_counts() > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544945c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254fb57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1).reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['localization'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa336d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    loc = df.iloc[i]['localization']\n",
    "    if loc == 'abdomen':\n",
    "        temp.append(tf.one_hot(0, 15))\n",
    "    elif loc == 'scalp':\n",
    "        temp.append(tf.one_hot(1, 15))\n",
    "    elif loc == 'lower extremity':\n",
    "        temp.append(tf.one_hot(2, 15))\n",
    "    elif loc == 'trunk':\n",
    "        temp.append(tf.one_hot(3, 15))\n",
    "    elif loc == 'upper extremity':\n",
    "        temp.append(tf.one_hot(4, 15))\n",
    "    elif loc == 'back':\n",
    "        temp.append(tf.one_hot(5, 15))\n",
    "    elif loc == 'neck':\n",
    "        temp.append(tf.one_hot(6, 15))\n",
    "    elif loc == 'face':\n",
    "        temp.append(tf.one_hot(7, 15))\n",
    "    elif loc == 'chest':\n",
    "        temp.append(tf.one_hot(8, 15))\n",
    "    elif loc == 'foot':\n",
    "        temp.append(tf.one_hot(9, 15))\n",
    "    elif loc == 'ear':\n",
    "        temp.append(tf.one_hot(10, 15))\n",
    "    elif loc == 'unknown':\n",
    "        temp.append(tf.one_hot(11, 15))\n",
    "    elif loc == 'hand':\n",
    "        temp.append(tf.one_hot(12, 15))\n",
    "    elif loc == 'acral':\n",
    "        temp.append(tf.one_hot(13, 15))\n",
    "    elif loc == 'genital':\n",
    "        temp.append(tf.one_hot(14, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3d05c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "one_hot_loc = np.array(temp)\n",
    "\n",
    "one_hot_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a5e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10015/10015 [05:51<00:00, 28.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# VGG-16\n",
    "preprocessed = []\n",
    "\n",
    "VGG_load = VGG16(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(VGG_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    #ohl = one_hot_loc[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(25088)\n",
    "\n",
    "    preprocessed.append(preds) #np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['VGG16'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afd33bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-32ad6cb7aa56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88325339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception\n",
    "preprocessed = []\n",
    "\n",
    "IV3_load = InceptionV3(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(IV3_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    ohl = one_hot_loc[i]\n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(131072)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['IV3'] = preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0493b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "preprocessed = []\n",
    "\n",
    "resnet_load = ResNet101V2(weights='imagenet', include_top=False)\n",
    "model = models.Sequential()\n",
    "model.add(resnet_load)\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\"\"\"\n",
    "for i in tqdm(range(0, 10015)):\n",
    "    file = df.iloc[i]['image_id']\n",
    "    ohl = one_hot_loc[i]    \n",
    "    \n",
    "    img = image.load_img('./Data/HAM10000_images/' + file + '.jpg', target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(100352)\n",
    "\n",
    "    preprocessed.append(np.concatenate((preds, ohl)))\n",
    "    \n",
    "df['resnet'] = preprocessed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff649448",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(0, 10015):\n",
    "    dx = df.iloc[i]['dx']\n",
    "    if dx == 'akiec':\n",
    "        labels.append(tf.one_hot(0, 7))\n",
    "    elif dx == 'bcc':\n",
    "        labels.append(tf.one_hot(1, 7))\n",
    "    elif dx == 'bkl':\n",
    "        labels.append(tf.one_hot(2, 7))\n",
    "    elif dx == 'df':\n",
    "        labels.append(tf.one_hot(3, 7))\n",
    "    elif dx == 'mel':\n",
    "        labels.append(tf.one_hot(4, 7))\n",
    "    elif dx == 'nv':\n",
    "        labels.append(tf.one_hot(5, 7))\n",
    "    elif dx == 'vasc':\n",
    "        labels.append(tf.one_hot(6, 7))\n",
    "        \n",
    "df['one_hot'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae4ccc",
   "metadata": {},
   "source": [
    "(Warning for Sunlight, increased risk of cancer) Actinic keratoses and intraepithelial carcinoma / Bowen's disease (__akiec__), 0\n",
    "\n",
    "(Skin cancer) basal cell carcinoma (__bcc__), 1\n",
    "\n",
    "(HARMLESS) benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, __bkl__), 2\n",
    "\n",
    "(HARMLESS) dermatofibroma (__df__),  3\n",
    "\n",
    "melanoma (__mel__),  4\n",
    "\n",
    "(Not entirely harmless) melanocytic nevi (__nv__)   5\n",
    "\n",
    "(HARMLESS) vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, __vasc__). 6 \n",
    "\n",
    "\n",
    "More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d4b2329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>VGG16</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[0.0, 0.0, 11.025155, 0.0, 0.08701746, 0.0, 0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[0.0, 0.0, 1.2555947, 0.72406036, 0.0, 0.0, 0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[0.0, 0.0, 6.3895617, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset                                              VGG16  risk  \n",
       "0  vidir_modern  [0.0, 0.0, 11.025155, 0.0, 0.08701746, 0.0, 0....   0.0  \n",
       "1  vidir_modern  [0.0, 0.0, 1.2555947, 0.72406036, 0.0, 0.0, 0....   0.0  \n",
       "2  vidir_modern  [0.0, 0.0, 6.3895617, 0.0, 0.0, 0.0, 0.0, 0.0,...   0.0  \n",
       "3  vidir_modern  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   0.0  \n",
       "4  vidir_modern  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   0.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk = []\n",
    "\n",
    "for i in range(0, 10015):\n",
    "    if df.iloc[i]['dx'] in ['bkl', 'df', 'vasc']:\n",
    "        risk.append(0.0)\n",
    "    elif df.iloc[i]['dx'] == 'nv':\n",
    "        risk.append(1.0)\n",
    "    elif df.iloc[i]['dx'] == 'akiec':\n",
    "        risk.append(2.0)\n",
    "    elif df.iloc[i]['dx'] in ['mel', 'bcc']:\n",
    "        risk.append(3.0)\n",
    "        \n",
    "df['risk'] = risk\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['risk'] == 3.0]['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9beeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dx\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bbc774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"risk\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f70f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save VGG without body parts\n",
    "pickle_out = open(\"VGG16_no_body.pickle\", \"wb\")\n",
    "pickle.dump(df[\"VGG16\"], pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load VGG without body parts\n",
    "pickle_in = open(\"VGG16_no_body.pickle\", \"rb\")\n",
    "z_vgg_no_body = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"VGG16.pickle\", \"wb\")\n",
    "pickle.dump(df[\"VGG16\"], pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"IV3.pickle\", \"wb\")\n",
    "pickle.dump(df[\"IV3\"], pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"resnet.pickle\", \"wb\")\n",
    "pickle.dump(df[\"resnet\"], pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"one_hot.pickle\", \"wb\")\n",
    "pickle.dump(df[\"one_hot\"], pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"risk.pickle\", \"wb\")\n",
    "pickle.dump(df[\"risk\"], pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b34f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"VGG16.pickle\", \"rb\")\n",
    "z_vgg = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"IV3.pickle\", \"rb\")\n",
    "z_iv3 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"resnet.pickle\", \"rb\")\n",
    "z_res = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1566b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"one_hot.pickle\", \"rb\")\n",
    "z_one_hot = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"risk.pickle\", \"rb\")\n",
    "z_risk = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_z = np.array(z_vgg)\n",
    "iv_z = np.array(z_iv3)\n",
    "res_z = np.array(z_res)\n",
    "one_hot_z = np.array(z_one_hot)\n",
    "risk_z = np.array(z_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bda12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"one_hot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96b7bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_X = np.array(df[\"VGG16\"])\n",
    "#IV3_X = np.array(z_iv3)\n",
    "#RES_X = np.array(z_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a30f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = np.array(df['one_hot'])\n",
    "\n",
    "y = np.array(z_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e255d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68fd79d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 4)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y = []\n",
    "for ele in y:\n",
    "    new_y.append(tf.one_hot(int(ele), 4))\n",
    "    \n",
    "new_y = np.array(new_y)\n",
    "\n",
    "new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a92e6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = models.Sequential()\n",
    "#vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(2048, activation='relu'))\n",
    "vgg_model.add(layers.Dense(1024, activation='relu',input_shape = [25088]))\n",
    "vgg_model.add(layers.Dense(512, activation='relu'))\n",
    "vgg_model.add(layers.Dense(128, activation='relu'))\n",
    "vgg_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3316d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_VGG = np.asarray(new_VGG).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c4503",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "804b36dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 25088)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG_X.shape\n",
    "\n",
    "new_VGG = []\n",
    "for i in range(0, 10015):\n",
    "    new_VGG.append(VGG_X[i])\n",
    "    \n",
    "new_VGG = np.array(new_VGG)\n",
    "new_VGG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_RES = []\n",
    "for i in range(0, 10015):\n",
    "    new_RES.append(RES_X[i])\n",
    "    \n",
    "new_RES = np.array(new_RES)\n",
    "new_RES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_IV3 = []\n",
    "for i in range(0, 10015):\n",
    "    new_IV3.append(IV3_X[i])\n",
    "    \n",
    "new_IV3 = np.array(new_IV3)\n",
    "new_IV3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5801ad0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9013 samples, validate on 1002 samples\n",
      "Epoch 1/10\n",
      "9013/9013 [==============================] - 3s 280us/sample - loss: 2.3665 - accuracy: 0.5930 - val_loss: 1.0121 - val_accuracy: 0.6527\n",
      "Epoch 2/10\n",
      "9013/9013 [==============================] - 2s 240us/sample - loss: 0.9012 - accuracy: 0.6756 - val_loss: 1.0545 - val_accuracy: 0.6477\n",
      "Epoch 3/10\n",
      "9013/9013 [==============================] - 2s 239us/sample - loss: 0.7666 - accuracy: 0.7157 - val_loss: 1.1179 - val_accuracy: 0.5858\n",
      "Epoch 4/10\n",
      "9013/9013 [==============================] - 2s 243us/sample - loss: 0.5896 - accuracy: 0.7807 - val_loss: 1.4790 - val_accuracy: 0.5818\n",
      "Epoch 5/10\n",
      "9013/9013 [==============================] - 2s 251us/sample - loss: 0.4364 - accuracy: 0.8388 - val_loss: 1.6604 - val_accuracy: 0.6267\n",
      "Epoch 6/10\n",
      "9013/9013 [==============================] - 2s 247us/sample - loss: 0.3247 - accuracy: 0.8804 - val_loss: 1.8702 - val_accuracy: 0.5150\n",
      "Epoch 7/10\n",
      "9013/9013 [==============================] - 2s 244us/sample - loss: 0.2517 - accuracy: 0.9109 - val_loss: 2.1672 - val_accuracy: 0.4671\n",
      "Epoch 8/10\n",
      "9013/9013 [==============================] - 2s 243us/sample - loss: 0.2167 - accuracy: 0.9270 - val_loss: 2.3328 - val_accuracy: 0.5798\n",
      "Epoch 9/10\n",
      "9013/9013 [==============================] - 2s 250us/sample - loss: 0.1402 - accuracy: 0.9532 - val_loss: 2.7641 - val_accuracy: 0.5888\n",
      "Epoch 10/10\n",
      "9013/9013 [==============================] - 2s 252us/sample - loss: 0.1475 - accuracy: 0.9551 - val_loss: 2.9783 - val_accuracy: 0.6088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16fd1b46048>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "vgg_model.fit(new_VGG, new_y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12e09e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save(\"VGG_Model_NoBody.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8426319",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = vgg_model.history.history['loss']\n",
    "val_loss = vgg_model.history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('VGG_Loss.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f97aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = vgg_model.history.history['accuracy']\n",
    "val_acc = vgg_model.history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.savefig('VGG_Acc.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = models.Sequential()\n",
    "#res_model.add(layers.Dense(8192, activation='relu'))\n",
    "#res_model.add(layers.Dense(4096, activation='relu'))\n",
    "#res_model.add(layers.Dense(2048, activation='relu'))\n",
    "res_model.add(layers.Dense(1024, activation='relu', input_shape = [100367]))\n",
    "res_model.add(layers.Dense(512, activation='relu'))\n",
    "res_model.add(layers.Dense(128, activation='relu'))\n",
    "res_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b87fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "res_model.fit(new_RES, new_y, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf2b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = res_model.history.history['loss']\n",
    "val_loss = res_model.history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('RES_Loss.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866e528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = res_model.history.history['accuracy']\n",
    "val_acc = res_model.history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.savefig('RES_Acc.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f258be9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"risk\")[\"localization\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model = models.Sequential()\n",
    "#iv3_model.add(layers.Dense(8192, activation='relu'))\n",
    "#iv3_model.add(layers.Dense(4096, activation='relu'))\n",
    "#iv3_model.add(layers.Dense(2048, activation='relu'))\n",
    "iv3_model.add(layers.Dense(1024, activation='relu', input_shape = [131087]))\n",
    "iv3_model.add(layers.Dense(512, activation='relu'))\n",
    "iv3_model.add(layers.Dense(128, activation='relu'))\n",
    "iv3_model.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6f400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iv3_model.compile(optimizer='Adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "              metrics=['accuracy'])\n",
    "iv3_model.fit(new_IV3, new_y, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = iv3_model.history.history['loss']\n",
    "val_loss = iv3_model.history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('IV3_Loss.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01563844",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = iv3_model.history.history['accuracy']\n",
    "val_acc = iv3_model.history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.savefig('IV3_Acc.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"VGG_weight.pkl\", \"rb\")\n",
    "VGG_weight = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_test = models.Sequential()\n",
    "#vgg_model.add(layers.Dense(8192, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(4096, activation='relu'))\n",
    "#vgg_model.add(layers.Dense(2048, activation='relu'))\n",
    "vgg_test.add(layers.Dense(1024, activation='relu',input_shape = [25088]))\n",
    "vgg_test.add(layers.Dense(512, activation='relu'))\n",
    "vgg_test.add(layers.Dense(128, activation='relu'))\n",
    "vgg_test.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_test.set_weights(VGG_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2cf12a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "24c401da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = image.load_img(file_path, target_size= (224,224))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "preds = model.predict(img).reshape(25088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7f43be13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25088,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8d10480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"ISIC_0024306.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "af8bc464",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = tf.keras.models.load_model(\"VGG_Model_NoBody.h5\", compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0012640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(img_path, Model):\n",
    "    #load preprocessing model\n",
    "    VGG_load = VGG16(weights='imagenet', include_top=False)\n",
    "    model = models.Sequential()\n",
    "    model.add(VGG_load)\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    #image preprocessing \n",
    "    img = image.load_img(img_path, target_size= (224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    preds = model.predict(img).reshape(25088)\n",
    "    \n",
    "    #predict cancer type\n",
    "    preds = Model.predict(np.array([preds]))\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a78c499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_classes_dict = {\n",
    "    0 : 'no risk',\n",
    "    1 : 'low risk',\n",
    "    2 : 'medium risk',\n",
    "    3 : 'high risk'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dcf81efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_predict(file_path , Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "05d06026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.2549977, -1.1524458,  7.3475866, -3.7016683], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1f07e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = preds.argmax(axis=-1)\n",
    "pr = lesion_classes_dict[pred_class]\n",
    "result =str(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "31e24604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medium risk'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00cce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
